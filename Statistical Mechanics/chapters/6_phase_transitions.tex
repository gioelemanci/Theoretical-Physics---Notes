\chapter{Phase Transitions}

Phase transitions are among the most striking manifestations of collective behavior in statistical physics.
They represent abrupt qualitative changes in the macroscopic state of matter that arise from the smooth variation of a few external control parameters, such as temperature, pressure, or magnetic field.
At the microscopic level, these transitions emerge from the cooperative dynamics of a very large number of interacting degrees of freedom, leading to singularities in thermodynamic quantities and to the spontaneous breaking of symmetries.

In this chapter, we develop the thermodynamic and statistical foundations needed to describe and classify phase transitions.
We begin by introducing the concept of a \textit{phase diagram}, which organizes the possible equilibrium states of a system and identifies coexistence regions where two or more phases can be in equilibrium.
We then derive the \textit{Clausius--Clapeyron equation}, which provides a quantitative description of coexistence curves and the relation between intensive thermodynamic variables along phase boundaries.

Next, we discuss the \textit{classification of phase transitions} according to the nature of the non--analyticity of the free energy, distinguishing between first--order transitions, characterized by discontinuities in first derivatives (such as latent heat or density jumps), and continuous or higher--order transitions, where thermodynamic quantities remain continuous but their derivatives diverge.
This classification naturally leads to the study of critical phenomena and universality.

Finally, to illustrate how these ideas emerge from microscopic models, we consider the paradigmatic example of the \textit{Ising model}.
Despite its simplicity, this lattice model captures the essential features of cooperative ordering and provides a concrete realization of a continuous phase transition, allowing us to connect the abstract thermodynamic description with a statistical–mechanical one.

Throughout this chapter, our aim is to bridge the phenomenological thermodynamics of phase transitions with their microscopic statistical interpretation, highlighting how non--analytic behavior in macroscopic observables originates from the collective organization of microscopic states.

\section{Phase Diagrams}

A classical fluid can exist in different phases—solid, liquid, and gas—depending on its temperature \(T\) and pressure \(p\). In the \(p-T\) diagram, these phases occupy distinct regions separated by phase boundaries, along which two phases can coexist in equilibrium.

\paragraph{Coexistence lines and triple point.}
In a phase diagram, the \textit{coexistence lines} (or phase boundaries) represent the set of thermodynamic states where two phases of the same substance can coexist in equilibrium. Along each line, the temperature, pressure, and chemical potential of the two phases are equal,
\[
    T_1 = T_2, \qquad p_1 = p_2, \qquad \mu_1 = \mu_2,
\]
ensuring that the transformation can occur reversibly under constant thermodynamic conditions.
These three coexistence lines meet at a unique point in the \(p\)--\(T\) plane called the \textit{triple point}, where solid, liquid, and vapor coexist simultaneously in thermodynamic equilibrium.
At this point, the equality of temperature, pressure, and chemical potential extends to all three phases,
\[
    T_\mathrm{s} = T_\mathrm{l} = T_\mathrm{v}, \qquad
    p_\mathrm{s} = p_\mathrm{l} = p_\mathrm{v}, \qquad
    \mu_\mathrm{s} = \mu_\mathrm{l} = \mu_\mathrm{v},
\]
so that mass can be exchanged among them without altering the macroscopic state of the system.
The triple point thus defines a fundamental reference in thermodynamics, often used for the calibration of temperature and pressure scales.

\begin{figure}[H]
    \begin{minipage}[b]{0.55\textwidth}
        \includegraphics[width=0.9\textwidth]{img/phase_diag_classical_fluid.png}
        \caption{A schematic phase diagram showing different phases of a classical fluid, with regions of solid, liquid, and gas separated by phase boundaries. Critical points and triple points are also indicated, along with the coexistence curves.}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.4\textwidth}
        The solid–liquid line marks the conditions of melting and freezing, while the liquid–vapor line corresponds to vaporization and condensation. The solid–vapor line instead represents sublimation and deposition processes. All three boundaries meet at the triple point, where the three phases coexist simultaneously in thermodynamic equilibrium. The liquid–vapor coexistence curve terminates at the critical point, beyond which the distinction between liquid and gas disappears and the substance forms a supercritical fluid. Each phase transition involves a discontinuous change in certain thermodynamic properties, such as density or enthalpy, and can be associated with a latent heat exchange between the phases.
    \end{minipage}
\end{figure}

\paragraph{Critical point and superfluidity.}
The \textit{critical point} marks the upper end of the liquid--vapor coexistence curve in the \(p\)--\(T\) diagram. At this point, the distinction between liquid and gas disappears: the densities of the two phases become equal, and the surface tension vanishes.
Beyond the critical point, the substance forms a \textbf{supercritical fluid}, a single homogeneous phase that exhibits properties intermediate between those of a liquid and a gas, such as high diffusivity combined with a relatively large density. The system does not dissipate energy from friction as a normal fluid would, allowing it to flow without viscosity.
The critical point is characterized by continuous (second--order) phase transition behavior, where response functions such as compressibility and heat capacity diverge according to universal critical exponents.

In certain quantum fluids, such as liquid helium--4, a different kind of continuous phase transition occurs at very low temperatures, leading to the onset of \textbf{superfluidity}.
\begin{figure}[H]
    \begin{minipage}[b]{0.4\textwidth}
        Below the so called $\lambda$--point (at \(T_\lambda \approx 2.17~\mathrm{K}\) under saturated vapor pressure), helium--4 undergoes a transition from the normal liquid phase (He~I) to the superfluid phase (He~II).
        The superfluid phase exhibits remarkable macroscopic quantum phenomena, including the absence of viscosity, the ability to flow through extremely narrow capillaries, and the quantization of vorticity.
        Although both the critical point and the superfluid transition correspond to continuous changes in the state of the system, they originate from different microscopic mechanisms: the former arises from the disappearance of density fluctuations at large scales, while the latter emerges from Bose--Einstein condensation of helium atoms.
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.55\textwidth}
        \includegraphics[width=0.9\textwidth]{img/phase_diag_4He.png}
        \caption{Schematic phase diagram of liquid helium-4, showing solid, liquid, gas, and superfluid regions separated by phase boundaries. Coexistence curves are indicated where appropriate, while the boundary between the liquid and superfluid phases is shown for reference, even though this transition is continuous.}
        \label{fig:phase_diag_4He}
    \end{minipage}
\end{figure}

\subsection{Clausius--Clapeyron Equation}

Consider a system at equilibrium along a coexistence line between two phases, denoted \(\alpha\) and \(\beta\).
The Gibbs free energy of the system is
\begin{equation}
    G(T,p) = \mu N,
    \label{eq:Gibbs_free_energy}
\end{equation}
where \(\mu\) is the chemical potential and \(N\) the number of particles.
Per particle, the Gibbs free energy is
\[
    g = \frac{G}{N} = \mu.
\]
At equilibrium along the coexistence line, the chemical potentials of the two phases are equal:
\[
    \mu_\alpha(T,p) = \mu_\beta(T,p) \quad \implies \quad g_\alpha(T,p) = g_\beta(T,p).
\]
Differentiating both sides along the coexistence line gives
\[
    \mathrm{d} \mu_\alpha = \mathrm{d} \mu_\beta,
\]
which, using the thermodynamic identity for the Gibbs free energy per particle\footnote{\(\mathrm{d} g = \mathrm{d} \mu = -s\,\mathrm{d}T + v\,\mathrm{d}p\) since \(\mathrm{d} G = \mu \mathrm{d}N + N \mathrm{d}\mu\), leading to the deletions which yield \(\mathrm{d}g = \mathrm{d}\mu\).}
\[
    \mathrm{d} \mu = -s \, \mathrm{d} T + v \, \mathrm{d} p,
\]
where \(s\) and \(v\) are the molar entropy and molar volume, respectively, we obtain
\[
    - s_\alpha \, \mathrm{d} T + v_\alpha \, \mathrm{d} p = - s_\beta \, \mathrm{d} T + v_\beta \, \mathrm{d} p.
\]
Now we can differentiate with respect to temperature:
\[
    \frac{\d{\mu}}{\d{T}} = \left(\frac{\partial \mu}{\partial T}\right)_p + \left(\frac{\partial \mu}{\partial p}\right)_T \frac{\d{p}}{\d{T}} = -s + v \frac{\mathrm{d} p}{\mathrm{d} T},
\]
and rewriting this, the slope of the coexistence curve in the \(p\)--\(T\) plane is
\[
    \frac{\mathrm{d} p}{\mathrm{d} T} = \frac{s_\beta - s_\alpha}{v_\beta - v_\alpha} = \frac{\Delta s}{\Delta v}.
\]
Introducing the \textbf{latent heat} \(q\) per mole, which is the heat absorbed or released during the phase transition at constant temperature and pressure, we have
\begin{equation}
    q = T \, \Delta s.
    \label{eq:latent_heat}
\end{equation}
Substituting this relation into the previous expression, we obtain the \textbf{Clausius--Clapeyron equation}:
\begin{equation}
    \frac{\mathrm{d} p}{\mathrm{d} T} = \frac{q}{T \, \Delta v}.
    \label{eq:Clausius_Clapeyron}
\end{equation}
This equation provides a fundamental link between measurable thermodynamic quantities along the coexistence line: the slope of the phase boundary is determined by the latent heat of the transition and the change in molar volume between the two phases.

\section{Classification of Phase Transitions}

Phase transitions can be broadly divided into two main categories: \textit{first--order} and \textit{continuous} (or \textit{second--order}) transitions, depending on the nature of the discontinuities that appear in the thermodynamic description of the system.

Historically, phase transitions were classified according to the \textit{Ehrenfest scheme}, which identified the order of the transition with the lowest derivative of the Gibbs free energy that exhibits a discontinuity.
Although this classification remains conceptually useful, it has been largely superseded by a more general framework developed in modern statistical mechanics, which highlights critical behavior and universality near continuous transitions.

\subsection{First--Order Phase Transitions}
First--order phase transitions are characterized by a discontinuous change in the first derivatives of the free energy with respect to the thermodynamic variables.
In particular, quantities such as volume or entropy experience finite jumps at the transition point.
These discontinuities imply the exchange of a finite amount of heat at constant temperature and pressure, known as the \textit{latent heat} of the transition:
\[
    q = T \, \Delta s,
\]
where \(\Delta s\) is the entropy difference between the two coexisting phases, as defined in \eqref{eq:latent_heat}.
First--order transitions are accompanied by the coexistence of phases and occur along well-defined lines in the \(p\)--\(T\) plane.
Typical examples include the melting of a solid, the vaporization of a liquid, and the sublimation of a solid into vapor.

\subsection{Continuous Phase Transitions}
Continuous (or second--order) phase transitions are characterized by the continuity of the first derivatives of the free energy, while higher-order derivatives become discontinuous or diverge.
No latent heat is involved, and the transition occurs smoothly, often associated with the emergence of long-range correlations and critical fluctuations.
Near the critical point, the system exhibits \textit{scale invariance} and \textit{universal behavior}, where macroscopic properties depend only on general features such as symmetry and dimensionality, rather than on microscopic details.
Examples include the liquid--gas critical point and the superfluid transition in helium--4.

\begin{remark}
    The presence or absence of latent heat provides a clear thermodynamic signature distinguishing first--order from continuous phase transitions.
    In first--order transitions, the system absorbs or releases a finite amount of energy to reorganize its microscopic structure, while in continuous transitions, this reorganization occurs gradually, with thermodynamic quantities varying smoothly but response functions (such as heat capacity or compressibility) diverging near the critical point.
\end{remark}

\section{Discontinuities and Phase Transitions}

Phase transitions are intimately connected with the analytic structure of the partition function.
For finite systems, \( \mathcal{Z}_N(\lambda) \) is an analytic function of its parameters, so true singularities cannot occur.
However, the distribution of its zeros in the complex plane reveals where non--analytic behavior may emerge in the thermodynamic limit.

This analytic mechanism was first formalized by Lee and Yang in a pair of theorems that establish both the existence and the analyticity properties of the thermodynamic potential in the complex plane of the control parameter.

\begin{theorem}[Lee--Yang I | Existence of the thermodynamic limit]
    Consider a system of \(N\) interacting particles with potential energy \(U_N\) satisfying the stability bound
    \[
        U_N \geq - K N , \qquad K > 0,
    \]
    and contained in a volume \(V\) whose boundary increases no faster than \(V^{2/3}\).
    Then, for any complex fugacity \(z = e^{\beta \mu}\), the limit
    \[
        \Psi(z,v,T) = \lim_{V \to \infty} \frac{1}{V} \log \mathcal{Z}(z,v,T)
    \]
    exists and defines a continuous, monotonically increasing function of \(z \in \mathbb{R}^+\).
\end{theorem}

\begin{theorem}[Lee--Yang II | Analyticity and distribution of zeros]
    Let \(R\) be an open subset of the complex \(z\)--plane containing a portion of the positive real axis.
    If, for all finite \(V\) and \(T\), the grand partition function \( \mathcal{Z}(z,v,T) \) has no zeros in \(R\),
    then the sequence \( (\log \mathcal{Z}(z,v,T))/V \) converges uniformly as \( V \to \infty \) in any closed subset of \(R\),
    and therefore the thermodynamic potential \( \Psi(z,v,T) \) is analytic in \(R\).
\end{theorem}

The two results together imply that a phase transition can only occur if, in the thermodynamic limit, a locus of zeros of the finite--volume partition function \(\mathcal{Z}(z,V,T)\) approaches the positive real axis.
The point \(z_c\) where this accumulation occurs divides the real axis into distinct analytic regions, corresponding to different thermodynamic phases.
At \(z = z_c\), the potential \( \Psi(z,v,T) \) remains continuous but becomes non--analytic:
a cusp singularity corresponds to a first--order phase transition, while higher--order singularities describe continuous phase transitions.
If we have regions where the zeroes of \(\mathcal{Z}\) do not accumulate near the real axis then there will ne no PT in that region.

\begin{remark}
    The celebrated \textit{Lee--Yang circle theorem} is a special case of this general framework, proved for the ferromagnetic Ising model, where all zeros of the partition function in the complex fugacity plane \( z = e^{-2\beta h} \) lie on the unit circle \( |z| = 1 \).
    In more general systems, such as lattice gases or fluids with realistic interactions, the zeros no longer lie on a perfect circle, yet their accumulation and contact with the real axis remain the universal analytic mechanism underlying phase transitions.
\end{remark}

To illustrate the qualitative content of the \textbf{first Lee--Yang theorem}, let us consider a system described by a mean--field Hamiltonian, for which the grand partition function can be written as a polynomial of finite degree \( N \) in the complex fugacity \( z \). Starting from the canonical partition function of a system with Hamiltonian
\[
    \mathcal{H} = \sum_i \frac{p_i^2}{2m} + U_N(q_1, \dots, q_N),
\]
we can integrate over the momenta and separate the purely configurational contribution:
\[
    Z_N(V,T) = \int_V \! \mathrm{d}\Omega \, e^{-\beta \mathcal{H}}
    = \frac{Q_N}{N!\,\lambda_{\mathrm{th}}^{3N}},
    \qquad
    Q_N(V,T) = \int \prod_i \mathrm{d}^3q_i \, e^{-\beta U_N(q_1,\dots,q_N)}.
\]
Here, \( Q_N \) encodes the interaction between particles, while the prefactor
\( 1/(N!\lambda_{\mathrm{th}}^{3N}) \) represents the contribution of indistinguishability and kinetic energy.

Hence, the grand partition function of the system reads
\[
    \mathcal{Z}_N(z)
    = \sum_{n=0}^N \frac{z^n Q_n}{n!\,\lambda_{\mathrm{th}}^{3n}}
    = \sum_{n=0}^N a_n z^n,
    \qquad a_n > 0 \ \forall n.
\]
At finite \( N \), this is a polynomial in \( z \) with positive coefficients.
Even before taking the thermodynamic limit, this already implies that the zeros of
\( \mathcal{Z}_N(z) \) cannot lie on the positive real axis, since all the coefficients
of the polynomial are strictly positive. Therefore, for any finite system, the grand
partition function is analytic and positive for \( z \in \mathbb{R}^+ \).

To examine whether the thermodynamic limit exists, we must ensure that the series
remains convergent as \( N \to \infty \). We assume, as in the standard proof, that
the interaction potential is bounded from below by a function linear in \( N \):
\[
    U_N \ge -K N, \qquad K > 0.
\]
This lower bound guarantees the system’s stability: the energy cannot decrease
faster than linearly with the number of particles. From this condition, it follows that
\[
    e^{-\beta U_N} \le e^{\beta K N}.
\]
Using this inequality, we can bound the configurational integral:
\[
    Q_N \le V^N e^{\beta K N}.
\]
Substituting this estimate into the series for \( \mathcal{Z}_N(z) \), we find
\[
    \mathcal{Z}_N(z)
    \le \sum_{n=0}^N
    \frac{1}{n!}
    \left( \frac{z V e^{\beta K}}{\lambda_{\mathrm{th}}^{3}} \right)^n
    \xrightarrow{N\to\infty}
    \exp\!\left( \frac{z V e^{\beta K}}{\lambda_{\mathrm{th}}^{3}} \right).
\]
The thermodynamic limit is therefore well defined: the grand partition function
approaches a continuous, positive, monotonically increasing function for all
\( z \in \mathbb{R}^+ \).

In summary, the essential point of the first Lee--Yang theorem is that,
under the assumption of thermodynamic stability (i.e., a potential bounded
from below), the grand partition function \( \mathcal{Z}(z) \) is analytic
for positive real fugacity and its thermodynamic limit is well defined.

The \textbf{second Lee--Young theorem} help us understand how singularities can appear in the thermodynamic limit: we have to focus on the logarithm of the grand partition function. All thermodynamic quantities, such as pressure, density, or free energy, are obtained from derivatives of
\[
    \Phi = \log \mathcal{Z} \implies \begin{dcases}
        p = k_B T \Psi(z,\,v,\,T), \\
        n = \frac{1}{v} = z \frac{\partial}{\partial z} \Psi(z,\,v,\,T) \Big|_{\beta}.
    \end{dcases}
\]
Therefore, the zeros of \( \mathcal{Z} \) correspond to singularities of \( \Phi \), and thus to possible singularities of thermodynamic observables. In other words, any non-analytic behaviour of macroscopic quantities must originate from points in the complex fugacity plane where \( \mathcal{Z} = 0 \).

From the previous discussion, we know that at finite \( N \) the grand partition function
\[
    \mathcal{Z}_N(z) = \sum_{n=0}^N a_n z^n, \qquad a_n > 0,
\]
is a polynomial with strictly positive coefficients.
\begin{figure}[H]
    \begin{minipage}[b]{0.55\textwidth}
        \begin{center}
            \begin{tikzpicture}[scale=1.5]
                \fill[green!30] (0,-0.1) rectangle (1.9,0.1);
                \node[right] at (0,-0.3) {Zeros-free region};

                \draw[->, thick] (-2,0) -- (2,0) node[right] {Re$(z)$};
                \draw[->, thick] (0,-2) -- (0,2) node[above] {Im$(z)$};

                \foreach \x/\y in {-1.5/0.8, -0.5/0.6, -1/-0.3, -1.2/-1.0, -0.8/1.3, -0.5/-0.9, -0.2/1.2,
                        0.4/-1.5, 0.7/1.0, 1.0/-0.8, 1.3/0.9, 1.6/-1.3} {
                        \filldraw[blue!70] (\x,\y) circle (1pt);
                    }

                \node[blue!70] at (1.6,1.6) {$z^{(i)}$ (zeros of $\mathcal{Z}_{N}(z)$)};
            \end{tikzpicture}
        \end{center}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.4\textwidth}
        By the fundamental theorem of algebra, it possesses \( N \) complex zeros, but since all coefficients are positive, none of these zeros can lie on the positive real axis. As a result, for any finite \( N \), \( \mathcal{Z}_N(z) \) is analytic and strictly positive for real positive \( z \), which means that no true phase transition can occur in a system of finite size. The partition function, and hence all thermodynamic functions derived from it, remain smooth and differentiable.
    \end{minipage}
\end{figure}


\begin{figure}[H]
    \begin{minipage}[b]{0.4\textwidth}
        However, the situation changes qualitatively in the thermodynamic limit \( N, V \to \infty \) with fixed density. As \( N \) increases, the zeros of \( \mathcal{Z}_N(z) \) in the complex \( z \)-plane can become denser and may start to accumulate along certain curves. In this limit, the set of zeros can form continuous lines or regions in the complex plane.
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.55\textwidth}
        \begin{center}

            \begin{tikzpicture}[font=\sffamily, >=latex]
                \fill[orange!30] (-2,-0.5) rectangle (2.8,0.5);

                \tikzset{
                    axis/.style = {->, thick},
                    zero/.style = {circle, fill=blue!70, inner sep=1.3pt},
                    ghostzero/.style = {circle, fill=black!40, inner sep=1pt},
                    acc/.style = {dashed, thick},
                }

                \draw[axis] (-3,0) -- (3,0) node[right] {$\Re (z)$};
                \draw[axis] (-2,-2) -- (-2,2) node[above] {$\Im (z)$};

                \draw[acc, gray!60] (-2.4,1.2) .. controls (-1.0,0.4) and (1.0,0.4) .. (2.3,1.2);
                \draw[acc, gray!60] (-2.4,-1.2) .. controls (-1.0,-0.4) and (1.0,-0.4) .. (2.3,-1.2);

                \foreach \x/\y in {-2.3/1.2, -1.7/0.9, -1.0/0.7, -0.5/0.4, 0.0/0.3, 0.5/0.4, 1.0/0.7, 1.6/1.1, 2.2/1.2}{
                        \node[zero] at (\x,\y) {};
                        \node[zero] at (\x,-\y) {};
                    }

                \fill[red] (0,0) circle (2pt);
                \node[below right, red] at (0,0) {$z_c$};

                \node[align=center, font=\footnotesize, gray!60] at (0.2,-1.6)
                {Zeros in the complex plane accumulate\\
                    toward the real axis as $V \to \infty$};

            \end{tikzpicture}
        \end{center}
    \end{minipage}
\end{figure}

If such a line of zeros \(z^{(i)}\) approaches the positive real axis, then the logarithm of the partition function, \( \Phi(z) = \log \mathcal{Z}(z)\), becomes non-analytic at the point \(z_c\) where the accumulation occurs:
\[
    z^{(i)} \in \mathbb{C} - \mathbb{R}^+, \quad z^{(i)} \xrightarrow{N\to \infty} z_c \in \mathbb{R}^+.
\]
This non-analyticity is precisely what we interpret as a phase transition.

Hence, the second Lee--Yang theorem provides a qualitative explanation for the origin of thermodynamic singularities: the partition function itself is always analytic for finite systems, but as the system size grows, its zeros in the complex fugacity plane can condense and ``pinch'' the real axis. The point where this happens marks the emergence of a macroscopic phase transition. If we can demonstrate that for an infinite volume the zeroes remain out of the considered region, then there will be no PT in this region.

\begin{remark}
    In practice, even though the Lee--Yang theorems show that true non--analyticities can only appear strictly in the thermodynamic limit, real systems with a large but finite number of particles can still exhibit apparent phase transitions.
    For instance, a small bottle of water can freeze or boil sharply, even though it contains a finite (and thus analytic) number of degrees of freedom. This happens because, for macroscopic \(N\), the zeros of the partition function \(\mathcal{Z}_N(z)\) already lie extremely close to the real axis.
    As a consequence, the derivatives of \(\log \mathcal{Z}_N\) can vary very rapidly near those quasi--singular points, producing an abrupt but smooth crossover that is experimentally indistinguishable from a genuine discontinuity.
\end{remark}

\section{Heisemberg Model}

The Ising model represents one of the simplest yet most profound models in statistical mechanics.
It captures the essential mechanism behind magnetic ordering, spontaneous symmetry breaking, and the appearance of phase transitions in systems composed of many interacting constituents.
Although originally conceived to describe ferromagnetism, its conceptual framework extends to a wide class of collective phenomena, from lattice gases to binary mixtures and neural networks.

In this chapter, we will start by analyzing the simplest possible case: a system of magnetic moments embedded in a crystalline solid lattice, each associated with a magnetic moment, but \textit{without} any interaction between the spins. This will be done with the Heisemberg model, which accounts for \(3D\)-spins.
This non-interacting model describes a collection of distinguishable atoms with magnetic moments oscillating in a thermal bath, where the total energy is determined solely by their coupling with an external magnetic field.
Such a system corresponds to a \textbf{paramagnet}, and its behavior can be completely understood within the framework of classical equilibrium statistical mechanics.

We will then introduce interactions between neighboring magnetic moments, which tend to align or anti-align depending on the sign of the coupling constant.
It is precisely this introduction of \textit{spin--spin interaction} that gives rise to the emergence of cooperative behavior and, eventually, to a phase transition between the paramagnetic and \textbf{ferromagnetic} phases.
Thus, the Ising model clearly illustrates how the collective properties of matter — such as magnetization and critical phenomena — arise from the interplay between microscopic interactions and thermal fluctuations.

\subsection{Non-interacting Magnetic Spins}

We consider a crystalline solid consisting of \(N\) atoms arranged on a regular lattice of fixed volume \(V\) and temperature \(T\).
Each lattice site hosts a single atom, whose center of mass is bound to oscillate around its equilibrium position due to thermal vibrations.

\begin{figure}[H]
    \begin{minipage}[b]{0.35\textwidth}
        \centering
        \begin{tikzpicture}[scale=1.2]
            \def\L{0.8}
            \def\nx{4}
            \def\ny{4}

            \foreach \i in {0,...,\nx}{
                    \foreach \j in {0,...,\ny}{
                            \ifnum\i<\nx
                                \draw[gray!50] (\i*\L, \j*\L) -- ({(\i+1)*\L}, \j*\L);
                            \fi
                            \ifnum\j<\ny
                                \draw[gray!50] (\i*\L, \j*\L) -- (\i*\L, {(\j+1)*\L});
                            \fi
                            \filldraw[blue!70] (\i*\L, \j*\L) circle (1.5pt);
                        }
                }
        \end{tikzpicture}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.6\textwidth}
        For the purpose of studying magnetic properties, we assume that these translational vibrations are small and can be effectively decoupled from the magnetic degrees of freedom.
        Each atom carries a \textit{magnetic moment} (or spin) represented by a three--dimensional vector \(\bs{\mu}_i\) of fixed magnitude \(\mu = |\bs{\mu}_i|\), free to orient in any direction in space. This is the characteristic of the \textbf{Heisemberg model}.
        Hence, the configuration space associated with the magnetic degrees of freedom of each atom is the surface of a sphere of radius \(\mu\).
    \end{minipage}
\end{figure}

The Hamiltonian of the system naturally separates into two distinct contributions:
\[
    \mathcal{H} = \mathcal{H}_{\text{kin}}(\{q_i, p_i\}) + \mathcal{H}_{\text{mag}}(\{\bs{\mu}_i\}),
\]
where \(\mathcal{H}_{\text{kin}}\) accounts for the kinetic and potential energy of the lattice vibrations, and \(\mathcal{H}_{\text{mag}}\) describes the interaction of the magnetic moments with external fields and, possibly, with one another.
Since our interest lies in the thermodynamic and collective magnetic properties, and the kinetic part merely contributes a multiplicative factor to the partition function, we will focus on the magnetic Hamiltonian \(\mathcal{H}_{\text{mag}}\).

\begin{remark}[Origin of the atomic magnetic moment]
    The magnetic moment of an atom originates from the microscopic motion of charged particles within it.
    In classical terms, a circulating electric charge produces a magnetic dipole moment; in quantum mechanics, this effect arises from two distinct contributions:
    \begin{enumerate}
        \item \textbf{Orbital motion of electrons:} each electron moving around the nucleus carries an orbital angular momentum $\mathbf{L}$, associated with a magnetic moment
              $\boldsymbol{\mu}_{\mathrm{orb}} = -\frac{e}{2m_e}\mathbf{L}$.
        \item \textbf{Intrinsic spin:} the electron possesses an intrinsic angular momentum $\mathbf{S}$, giving rise to a spin magnetic moment
              $\boldsymbol{\mu}_{\mathrm{spin}} = -g_s \frac{e}{2m_e}\mathbf{S}$, where $g_s \simeq 2.0023$ is the spin $g$-factor.
    \end{enumerate}
    The total magnetic moment of an atom is the vector sum of these contributions, weighted by the number and configuration of electrons. In many materials, the magnetic moments of different atoms are randomly oriented, leading to no macroscopic magnetization. However, when an external magnetic field is applied, these moments tend to align with it, giving rise to the paramagnetic response described by the Curie law.
\end{remark}

To describe the orientation of a magnetic moment in space, it is convenient to adopt spherical coordinates.
We can parametrize each moment as
\[
    \bs{\mu}_i = \mu (\sin\theta_i \cos\phi_i,\, \sin\theta_i \sin\phi_i,\, \cos\theta_i),
\]
where \(\phi_i \in [0, 2\pi)\) is the azimuthal angle and \(\theta_i \in [0, \pi]\) the polar angle.
\begin{figure}[H]
    \begin{minipage}[b]{0.55\textwidth}
        Within this framework, the pair \((\phi_i, \cos\theta_i)\) can be regarded as a set of generalized canonical variables \((q_i, p_i)\) for the rotational degrees of freedom of each magnetic moment, since the conjugate momentum to the coordinate \(\phi_i\) is proportional to \(\cos\theta_i\).
        This representation allows for a compact and geometrically intuitive formulation of the magnetic phase space as a product of \(N\) spheres:
        \[
            \mathcal{M}_{\text{mag}} = \bigotimes^N(S_2).
        \]
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.4\textwidth}
        \centering
        \begin{tikzpicture}[scale=1.1,>=Stealth]

            % Coordinate axes
            \draw[->] (0,0) -- (2.5,0) node[below] {$y$};
            \draw[->] (0,0) -- (0,2.5) node[left] {$z$};
            \draw[->] (0,0) -- (-1.2,-1.2) node[below] {$x$};

            % Sphere
            \draw[blue!60] (0,0) circle (2cm);
            \draw[blue!60] (0,0) ellipse (2cm and 0.7cm);
            \draw[blue!60] (0,2) arc (90:-90:0.5 and 2);
            \draw[blue!60] (0,2) arc (90:-90:-0.5 and 2);
            \node[blue!60] at (1,2.1) {$S_2$};

            % Theta angle in xy-plane
            \draw[-, purple] (-0.4,-0.4) arc (-120:-31:.75);
            \node[purple] at (0.8,-0.3) {$\phi$};

            % Phi angle from z-axis
            \draw[-, green!70!black] (0,1.0) arc (90:40:1.0);
            \node[green!70!black] at (0.3,1.1) {$\theta$};

            % Magnetic moment vector
            \draw[->,thick,orange] (0,0) -- (1.3,1.1) node[midway, below right] {$\bs{\mu}$};

            % Projection onto xy-plane
            \draw[dashed,gray] (1.3,1.1) -- (1.3,-0.3); % vertical drop
            \draw[->,gray] (0,0) -- (1.3,-0.3);     % projection vector

            % Origin dot
            \filldraw[black] (0,0) circle (1pt);
            \node[left] at (0,0) {$O$};

        \end{tikzpicture}
    \end{minipage}
\end{figure}

For a lattice of non-interacting magnetic moments, if we consider an external magnetic field
$\mathbf{H} = H \hat{\mathbf{z}}$ applied to the system, the magnetic part of the Hamiltonian reads:
\begin{equation}
    \mathcal{H}_{\mathrm{mag}}(\{\bs{\mu}_i\}) = - \sum_{i=1}^N \bs{\mu}_i \cdot \mathbf{H}.
    \label{eq:Heisenberg_magnetic_hamiltonian}
\end{equation}
The negative sign ensures that the lowest energy configuration corresponds to spins aligned with the field.
Since the spins do not interact, the partition function factorizes:
\[
    Z_N = (Z_1)^N,
\]
where the single-spin partition function is
\[
    \begin{aligned}
        Z_1 & = \int_{S_2} \mathrm{d}\Omega \, e^{-\beta \mathcal{H}_{\mathrm{mag}}(\bs{\mu})}
        = \int_0^\pi \mathrm{d}\theta \, \sin\theta \int_0^{2\pi} \mathrm{d}\phi \, e^{\beta H \mu \cos\theta} \\
            & = 2\pi \int_0^\pi \mathrm{d}\theta \, \sin\theta \, e^{\beta H \mu \cos\theta}
        = 2\pi \int_{-1}^{1} \mathrm{d}(\cos\theta) \, e^{\beta H \mu \cos\theta}                              \\
            & = \frac{2\pi}{\beta H \mu} \left( e^{\beta H \mu} - e^{-\beta H \mu} \right)
        = 4\pi \frac{\sinh(\beta H \mu)}{\beta H \mu}.
    \end{aligned}
\]
Thus, the total partition function is
\begin{equation}
    Z_N = \left( 4\pi \frac{\sinh(\beta H \mu)}{\beta H \mu} \right)^N,
    \quad \Rightarrow \quad
    \log Z_N = N \log\left( 4\pi \frac{\sinh(\beta H \mu)}{\beta H \mu} \right).
    \label{eq:Heisenberg_partition_potential}
\end{equation}
From this, we can compute the thermodynamic quantities:
\begin{itemize}
    \item Free energy:
          \[
              F = - \frac{1}{\beta} \log Z_N = - N k_B T \log\left( 4\pi \frac{\sinh(\beta H \mu)}{\beta H \mu} \right),
          \]

    \item Internal energy:
          \[
              \begin{aligned}
                  E & = - \frac{\partial}{\partial \beta} \log Z_N
                  = - N \frac{\partial}{\partial \beta} \log\left( \frac{\sinh(\beta H \mu)}{\beta H \mu} \right) \\
                    & = - N \left[ \frac{\mu H \cosh(\beta \mu H)}{\sinh(\beta \mu H)} - \frac{1}{\beta} \right]
                  = - N \mu H \left[ \coth(\beta \mu H) - \frac{1}{\beta \mu H} \right]
              \end{aligned}
          \]

    \item Entropy:
          \[
              S = \frac{E-F}{T} = k_B \beta (E-F) = Nk_B \left[ \log\left( 4\pi \frac{\sinh(\beta \mu H)}{\beta \mu H} \right) - \beta \mu H \coth(\beta \mu H) + 1 \right].
          \]
\end{itemize}

\paragraph{Zero temperature limit ($T \to 0$, $\beta \to \infty$):}
At very low temperatures, $\beta \mu H \gg 1$, we have $\coth(\beta \mu H) \to 1$, so
\[
    E(T \to 0) \simeq -N\mu H + 0 = -N \mu H.
\]
This corresponds to all spins perfectly aligned with the external field, i.e., the system is in its \textbf{ground state} with minimal energy.

\paragraph{High temperature limit ($T \to \infty$, $\beta \to 0$):}
For $\beta \mu H \ll 1$, we expand $\coth(\beta \mu H) \simeq \frac{1}{\beta \mu H} + \frac{\beta \mu H}{3} + \dots$\footnote{The Taylor expansion of the hyperbolic cotangent around $x=0$ is \(\coth(x) = \frac{1}{x} \left(1 + \frac{x^2}{3} \right) + \mathcal{O}(x^2)\).}, giving
\[
    E(T \to \infty) \simeq - N \mu H \left( \frac{1}{\beta \mu H} - \frac{\beta \mu H}{3} - \frac{1}{\beta \mu H} \right) = 0.
\]
In this limit, thermal fluctuations dominate and the spins are \textbf{randomly oriented}, leading to a vanishing average magnetic energy.

In summary at $T=0$ the system is fully ordered along the field (maximal magnetization), while at $T\to \infty$ the system is completely disordered due to thermal agitation, so the magnetic energy averages to zero.

As it is easy to notice, our system will never undergo a phase transition, since all this quantities are analytical and do not present any discontinuities or singularities; we have to introduce interactions in order to get our system to be able to undergo a "change of state". But before doing that it is very useful to define a quantity that can help us understand the system dynamics better: the \textbf{Magnetization}, which will behave as the \textit{order parameter} of the system.

\subsection{Magnetization}

The total magnetization of the system is defined as the sum of the magnetic moments of all spins:
\begin{equation}
    M = \langle \sum_{i=1}^N \bs{\mu}_i \rangle_c.
    \label{eq:magnetization_definition}
\end{equation}
In the canonical ensemble, the thermal average is expressed as
\[
    \begin{aligned}
        \frac{1}{Z_N} \int \d{\Omega_N} \left( \sum_{i=1}^N \bs{\mu}_i \right) e^{\beta \sum_{i=1}^N \bs{\mu}_i \cdot \mathbf{H}} = \frac{1}{\beta Z_N} \left(\frac{\partial}{\partial H}\right) \int \d{\Omega_N} e^{\beta \sum_{i=1}^N \bs{\mu}_i \cdot \mathbf{H}} \\
        = \frac{1}{\beta Z_N} \left( \frac{\partial}{\partial H} Z_N \right) = \frac{1}{\beta} \frac{\partial}{\partial H} \log(Z_N) = - \frac{\partial F}{\partial H} = N \mu \left[ \coth(\beta \mu H) - \frac{1}{\beta \mu H} \right].
    \end{aligned}
\]

\paragraph{Zero temperature limit ($T \to 0$, $\beta \to \infty$):}
At very low temperatures, thermal fluctuations are negligible compared to the interaction with the external field. In this limit, $\beta \mu H \gg 1$ and $\coth(\beta \mu H) \to 1$, so
\[
    M \simeq N \mu \left( 1 - 0 \right) = N \mu.
\]
All spins align with the external field, reaching the \textbf{saturation magnetization}. This represents the \textit{ground state} of the system, in which the magnetic energy is minimized and thermal disorder is absent.

\paragraph{High temperature limit ($T \to \infty$, $\beta \to 0$):}
At high temperatures, thermal energy dominates over the interaction with the field. For $\beta \mu H \ll 1$, we expand
\[
    \coth(\beta \mu H) \simeq \frac{1}{\beta \mu H} + \frac{\beta \mu H}{3} + \dots,
\]
giving
\[
    M \simeq N \mu \frac{\beta \mu H}{3} = \frac{N \mu^2}{3 k_B T} H,
\]
but zero in the first order.
Thermal fluctuations randomize the orientations of the spins, leading to a small net magnetization. The proportionality constant
\begin{equation}
    C = \frac{N \mu^2}{3 k_B},
    \label{eq:curie_coefficient}
\end{equation}
is called the \textbf{Curie coefficient}, and the relation
\begin{equation}
    M \simeq \frac{C}{T} H,
    \label{eq:curie_law}
\end{equation}
is the classical \textbf{Curie law} for paramagnets. It highlights that in the high-temperature regime, the magnetization decreases inversely with temperature, reflecting the competition between thermal disorder and alignment with the field. This constant is connected to the \textit{magnetic susceptibility}:
\begin{equation}
    \chi = \frac{\partial M}{\partial H},
    \label{eq:magnetic_susceptibility_definition}
\end{equation}
because in this regime we find that
\[
    \chi \xrightarrow{T \to \infty} \frac{M}{H} = \frac{C}{T}.
\]

\subsection{Interacting Magnetic Spins}

To understand the emergence of phase transitions, it is essential to include \textit{interactions} among the magnetic moments of the lattice. In real materials, atomic magnetic moments do not behave independently: the orientation of each spin tends to influence its nearest neighbours through short-range exchange interactions.

If we consider such local couplings, the magnetic Hamiltonian can be written as
\[
    \mathcal{H}_{\mathrm{mag}} = -\sum_{i=1}^N \bs{\mu}_i \cdot \mathbf{H}
    - J \sum_{\langle ij \rangle} \bs{\mu}_i \cdot \bs{\mu}_j,
\]
where the first term describes the interaction with the external magnetic field \(\mathbf{H}\), while the second term accounts for spin–spin interactions between nearest neighbours, denoted by the notation \(\langle ij \rangle\).
The number of nearest neighbours of each lattice site defines the \textbf{coordination number} \(z\), which depends on the lattice geometry (for example, \(z=2\) in one dimension, \(z=4\) for the square lattice, and \(z=6\) for the triangular lattice).

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[scale=0.5, every node/.style={inner sep=1pt}]
        % === 1D lattice ===
        \begin{scope}[xshift=0cm]
            \foreach \x in {1,...,5} {
                    \fill[gray!70] (\x,2) circle (2pt);
                }
            \fill[red] (3,2) circle (2.2pt);
            \fill[blue] (2,2) circle (2.2pt);
            \fill[blue] (4,2) circle (2.2pt);
        \end{scope}

        % === 2D square lattice ===
        \begin{scope}[xshift=7.5cm]
            \foreach \x in {0,...,4} {
                    \foreach \y in {0,...,4} {
                            \fill[gray!70] (\x,\y) circle (2pt);
                        }
                }
            \fill[red] (2,2) circle (2.2pt);
            \fill[blue] (2,1) circle (2.2pt);
            \fill[blue] (2,3) circle (2.2pt);
            \fill[blue] (1,2) circle (2.2pt);
            \fill[blue] (3,2) circle (2.2pt);
        \end{scope}

        % === 2D triangular lattice ===
        \begin{scope}[xshift=15cm]
            \foreach \y in {0,...,4} {
                    \foreach \x in {0,...,4} {
                            \fill[gray!70] (\x + 0.5*\y, \y*0.866) circle (2pt);
                        }
                }
            \fill[red] (2 + 0.5*2, 2*0.866) circle (2.2pt);
            \fill[blue] (2 + 0.5*1, 1*0.866) circle (2.2pt);
            \fill[blue] (3 + 0.5*1, 1*0.866) circle (2.2pt);
            \fill[blue] (1 + 0.5*2, 2*0.866) circle (2.2pt);
            \fill[blue] (3 + 0.5*2, 2*0.866) circle (2.2pt);
            \fill[blue] (2 + 0.5*3, 3*0.866) circle (2.2pt);
            \fill[blue] (1 + 0.5*3, 3*0.866) circle (2.2pt);
        \end{scope}
    \end{tikzpicture}
    \begin{minipage}[t]{0.8\textwidth}
        \caption{Comparison of coordination numbers \(z\) for lattices of increasing dimensionality:
            (a) one-dimensional chain (\(z=2\)),
            (b) two-dimensional square lattice (\(z=4\)),
            (c) two-dimensional triangular lattice (\(z=6\)), which has the same coordination number as a simple cubic lattice in \(3D\).}
    \end{minipage}
    \label{fig:lattice_comparison}
\end{figure}

\paragraph{Ferromagnetic and Paramagnetic Couplings.}
The sign of the coupling constant \(J\) determines the nature of the interaction:
\begin{itemize}
    \item For \(J > 0\), the energy is minimized when neighbouring spins are \textit{aligned}, leading to a \textbf{ferromagnetic} interaction. At sufficiently low temperatures, this cooperative tendency gives rise to \textit{spontaneous magnetization}, even in the absence of an external field.
    \item For \(J < 0\), the energy is minimized when neighbouring spins are \textit{anti-aligned}, leading to an \textbf{antiferromagnetic} interaction. The resulting long-range order alternates between up and down spins, producing a vanishing net magnetization.
\end{itemize}
In the absence of spin–spin interactions (\(J = 0\)), the system reduces to an ideal \textbf{paramagnet}, where spins respond independently to the external field and no cooperative ordering occurs.

\paragraph{The Ising Simplification.}
The full vector model above, known as the \textbf{Heisenberg model}, is generally difficult to solve analytically because spins can point in any direction on the unit sphere, and the interaction term involves continuous degrees of freedom.
A powerful simplification is obtained by restricting each magnetic moment to take only two possible orientations along a fixed axis (conventionally the \(z\)-axis):
\[
    \bs{\mu}_i = \pm \mu \, \hat{\mathbf{z}}.
\]
This leads to the \textbf{Ising model}, where each spin is represented by a discrete variable \(\sigma_i = \pm 1\), and the Hamiltonian becomes
\[
    \mathcal{H}_{\mathrm{Ising}} = -\mu H \sum_i \sigma_i - \mu^2 J \sum_{\langle ij \rangle} \sigma_i \sigma_j.
\]
Despite its simplicity, this model captures the essential physics of cooperative phenomena and phase transitions in magnetic systems.

\begin{remark}
    The Ising model, though based on a binary spin variable, provides a universal paradigm for studying critical phenomena. Its conceptual importance lies in showing that sharp macroscopic transitions — such as the onset of magnetization — can emerge from the collective behaviour of many microscopic degrees of freedom interacting through local rules.
    Moreover, the Ising model’s simplicity makes it a cornerstone not only in statistical mechanics, but also in diverse fields such as neural networks, lattice gases, and social dynamics, wherever binary interactions play a central role.
\end{remark}

Notice that, in this discrete formulation, the system no longer possesses a continuous phase space. Instead, its microstates form a finite ensemble of configurations given by all possible combinations of up and down spins on the lattice.

\section{Ising Model}

Consider a hypercubic lattice whose sites carry discrete variables
\(\sigma_i = \pm 1\). The Ising Hamiltonian
\begin{equation}
    \mathcal{H}_{\mathrm{Ising}}
    = - H \sum_i \sigma_i
    - J \sum_{\langle ij \rangle} \sigma_i \sigma_j,
    \label{eq:Ising_Hamiltonian}
\end{equation}
where \(J>0\) favors configurations in which nearest--neighbor spins are aligned, while the external field \(H\) tends to align the spins along its direction; we are considering for simplicity \(\mu = 1\).

To determine the equilibrium state, we minimize the free energy
\[
    F = E - TS = \langle \mathcal{H} \rangle
    - T \bigl(k_B \log \Gamma(E)\bigr),
\]
which makes explicit the competition between the internal energy \(E\) and the entropy \(S\). Energetically favorable states have aligned spins (low \(E\)), whereas entropy favors disordered configurations (high \(S\)). These two contributions typically push the system in opposite directions, and the temperature controls the relative weight of the entropic term.
Thus, \(T\) emerges as the key parameter that determines which term dominates in the minimization of the free energy, and consequently which phase---ordered or disordered—the system will adopt.
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[scale=1.1]

        \draw[->] (-4,0) -- (4,0) node[right] {$T$};

        \draw[thick] (0,0) -- (0,0.2);
        \node[below] at (0,-0.05) {$T_c$};

        \node[below] at (-2.2, 1.5) {Ferromagnetic};
        \node[below] at ( 2.2, 1.5) {Paramagnetic};

        \node[below] at ( 2.2, -0.1) {\small high \(E\) and \(S\)};
        \node[below] at ( 2.2, -0.4) {\small low \(F\) at high \(T\)};
        \node[below] at (-2.2, -0.1) {\small low \(E\) and \(S\)};
        \node[below] at (-2.2, -0.4) {\small low \(F\) at low \(T\)};

        \foreach \x in {-3.7,-3.2,-2.7,-2.2,-1.7,-1.2,-0.7} {
                \draw[->,>=stealth,thick, green!70!black] (\x,0.2) -- (\x,0.8);
            }

        \draw[->,>=stealth,thick, red!70!black] (0.7,0.2) -- +(0,0.6);   % up
        \draw[->,>=stealth,thick, red!70!black] (1.2,0.2) -- +(0,0.6);   % up
        \draw[->,>=stealth,thick, red!70!black] (1.7,.8) -- +(0,-0.6);  % down
        \draw[->,>=stealth,thick, red!70!black] (2.2,0.2) -- +(0,0.6);   % up
        \draw[->,>=stealth,thick, red!70!black] (2.7,.8) -- +(0,-0.6);  % down
        \draw[->,>=stealth,thick, red!70!black] (3.2,.8) -- +(0,-0.6);  % down
        \draw[->,>=stealth,thick, red!70!black] (3.7,0.2) -- +(0,0.6);   % up
    \end{tikzpicture}
\end{figure}
If we inspect the Ising phase diagram (see figure~\ref{fig:Ising_phase_diagram}), we immediately recognize the typical signature of a phase transition: a thermodynamic quantity develops a discontinuity at a specific value of the control parameters. Whenever such a non-analytic behaviour appears, a phase transition takes place. To distinguish the different phases, we introduce a quantity whose expectation value can indicate the degree of order in the system: the \textbf{order parameter}. For the Ising model---as well as for the Heisenberg model—the natural choice is the \textit{magnetization}.
Its behaviour clearly displays a discontinuity near the critical temperature, separating the ferromagnetic and paramagnetic regimes. Above \(T_c\) the magnetization vanishes, while below \(T_c\) it acquires two opposite non-zero values (corresponding to the two possible orientations of the ferromagnetic phase):
\[
    M =
    \begin{dcases}
        0,             & \text{if } T \geq T_c, \\
        M_0(T) \neq 0, & \text{if } T < T_c.
    \end{dcases}
\]
Thus the magnetization not only signals the phase transition but also encodes the ordering properties of the system.
If we look at the \(M\)-\(H\) diagram, we can also observe the appearance of the \textit{hysteresis loop} in the ferromagnetic phase. When a ferromagnet is magnetized and the external field is subsequently removed, the magnetization does not relax back to zero but to a finite residual value—an effect absent in the paramagnetic phase.
\begin{figure}[H]
    \begin{minipage}{0.55\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{img/Ising_phase_diagram.png}
        \caption{Schematic phase diagram of the Ising model, showing the relationship between magnetization \(M\), external field \(H\), and temperature \(T\). The critical temperature \(T_c\) marks the boundary between the ferromagnetic (ordered) and paramagnetic (disordered) phases.}
        \label{fig:Ising_phase_diagram}
    \end{minipage}
    \hfill
    \begin{minipage}{0.4\textwidth}
        Another key feature of phase transitions is the rate at which the order parameter changes as the system approaches the critical point. Close to \(T_c\), the magnetization exhibits a power-law behaviour:
        \[
            M(T \to T_c) \sim |T - T_c|^{\beta},
        \]
        where \(\beta\) is the \textbf{critical exponent} of the magnetization, characterizing how sharply the transition occurs.

        Finally, it is useful to anticipate how symmetries enter the description of phase transitions. When the external field is turned off (\(H=0\)) and the temperature is above the critical value (\(T > T_c\)), the Hamiltonian is invariant under a global \(\mathbb{Z}_2\) transformation (under flipping of all spins).
    \end{minipage}
\end{figure}
Below \(T_c\), however, the system develops a non-zero magnetization \(M \neq 0\), and the symmetry is no longer reflected in the equilibrium state: it is \textit{spontaneously broken}, without the need for any explicit symmetry-breaking term.

\subsection{Mean-Field Treatment}

The mean-field approach is a powerful approximation scheme that allows us to decouple interacting degrees of freedom by replacing the effect of all neighbours with an average, or \textbf{mean field}. Since the Ising model is exactly solvable only in \(1D\) (and in \(2D\) only for \(H=0\)), while for \(3D\) and higher dimensions no closed-form solution exists, we need an approximation scheme to obtain a tractable and physically meaningful solution.

We start from the partition function:
\[
    Z_N = \sum_{\{\sigma_i\}} e^{-\beta \mathcal{H}},
    \qquad
    \mathcal{H} = -J \sum_{\langle ij \rangle} \sigma_i \sigma_j - H \sum_{i} \sigma_i,
\]
and we immediately observe that the Hamiltonian cannot be written as a sum of independent single-spin contributions because of the nearest–neighbour interaction term.
The key idea of the mean-field approximation is to replace the interaction \(\sigma_i \sigma_j\) with an approximate expression depending only on the average magnetization \(m\).
With this replacement, the Hamiltonian becomes effectively decoupled and takes the form
\[
    Z_N^{(\mathrm{mf})} \simeq \sum_{\{\sigma_i\}}
    e^{-\beta \mathcal{H}^{(\mathrm{mf})}},
    \qquad
    \mathcal{H}^{(\mathrm{mf})} =
    N \frac{J z m^2}{2} - (J z m + H)\sum_i \sigma_i,
\]
where \(z\) is the coordination number of the lattice. In this form, the Hamiltonian is fully factorized into single-spin contributions.

Before carrying out the explicit computation, it is useful to summarize the logic of the procedure. We will first approximate the interaction term \(\sigma_i \sigma_j\) up to a suitable order in fluctuations around the average magnetization. We then reorganize the Hamiltonian until it becomes factorized. Finally, we compute the single-spin partition function, from which the full partition function follows as its \(N\)-th power.

\paragraph{Magnetization per spin \(m\).}
We introduce here the quantity that will play a central role in the mean-field construction: the \textit{average magnetization per spin}. It measures the degree of alignment of the system and will serve as the parameter around which we expand the interaction term:
\[
    \begin{aligned}
        m
         & = \frac{M}{N}
        = \frac{\left\langle \sum_{i} \sigma_i \right\rangle}{N}
        = \frac{1}{N}
        \sum_{\{\sigma_i\}}
        \left( \sum_{i} \sigma_i \right)
        \frac{e^{-\beta \mathcal{H}(\{\sigma_i\})}}{Z_N}            \\
         & = \frac{1}{Z_N \beta N}
        \sum_{\{\sigma_i\}}
        \frac{\partial}{\partial H}
        \left[
            e^{-\beta \left(
                    -H\sum_i \sigma_i
                    - J \sum_{\langle ij \rangle} \sigma_i \sigma_j
                    \right)}
        \right]                                                     \\
         & = \frac{1}{\beta N} \frac{\partial}{\partial H} \log Z_N
        = -\frac{1}{N}\frac{\partial F}{\partial H}.
    \end{aligned}
\]
This expression shows that the magnetization is the thermodynamic conjugate variable to the external field \(H\), and it will naturally emerge as the self-consistent order parameter in the mean-field approximation.

\paragraph{Mean field and partition function.}
We are now ready to apply the mean-field approximation. The idea is the following: instead of treating the interaction of each spin \(\sigma_i\) with its nearest neighbours exactly, we replace the surrounding spins by an average field, effectively producing a new \textbf{mean magnetization field}. In practice, we rewrite each spin as
\[
    \sigma_i \to \sigma_i + m - m = m + (\sigma_i - m),
\]
so that fluctuations appear only through the deviation \(\sigma_i - m\).
A preliminary approximation follows from the definition of the magnetization:
\[
    m = \frac{\langle \sum_{i} \sigma_i \rangle}{N}
    \sim \frac{\sum_{i} \langle \sigma_i \rangle}{N}
    = \langle \sigma_i \rangle,
\]
where we have exploited translational invariance.
We now expand the interaction term and neglect contributions of higher order in the fluctuations:
\[
    \begin{aligned}
        \sigma_i \sigma_j
         & = [m + (\sigma_i - m)][m + (\sigma_j - m)]                               \\
         & = m^2 + m(\sigma_i - m) + m(\sigma_j - m) + (\sigma_i - m)(\sigma_j - m) \\
         & \sim m^2 + m(\sigma_i + \sigma_j) - 2m^2
        = m(\sigma_i + \sigma_j) - m^2,
    \end{aligned}
\]
which corresponds to assuming that the fluctuations \(\sigma_i - m\) are small with respect to \(m\).
With this approximation the Hamiltonian becomes decoupled:
\[
    \begin{aligned}
        \mathcal{H}(\{\sigma_i\})
         & = -J \sum_{\langle ij \rangle} \sigma_i \sigma_j - H \sum_{i} \sigma_i               \\
         & \sim -J \sum_{\langle ij \rangle} (m(\sigma_i + \sigma_j)-m^2) - H \sum_{i} \sigma_i \\
         & = J \frac{Nz}{2} m^2 -J\sum_{\langle ij \rangle} 2m\sigma_i - H \sum_{i} \sigma_i,
    \end{aligned}
\]
where we used that the number of nearest--neighbour pairs is \(\frac{Nz}{2}\).
We also used that each \(\sigma_i\) appears twice in the sum over pairs, hence
\(\sum_{\langle ij \rangle} (\sigma_i + \sigma_j) = \sum_{\langle ij \rangle} 2\sigma_i\).
Continuing the computation:
\[
    \begin{aligned}
        \mathcal{H}(\{\sigma_i\})
         & = J \frac{Nz}{2} m^2 -J\sum_{\langle ij \rangle} 2m\sigma_i - H \sum_{i} \sigma_i \\
         & = J \frac{Nz}{2} m^2
        + \sum_{i} \left( -J \frac{z}{2} 2m \sigma_i -H \sigma_i\right)                      \\
         & =  \sum_{i} \left[ J \frac{z}{2} m^2 - \left( Jzm + H \right)\sigma_i \right],
    \end{aligned}
\]
since each \(\sigma_i\) is counted \(\frac{z}{2}\) times among the nearest--neighbour pairs.
At this stage the Hamiltonian is explicitly factorized into single-spin contributions, and we may therefore introduce the single-spin mean-field Hamiltonian
\begin{equation}
    \mathcal{H}^{(mf)}(\sigma_i) = J \frac{z}{2} m^2 - \left( Jzm + H \right)\sigma_i.
    \label{eq:mean_field_Hamiltonian_single_spin}
\end{equation}
The canonical partition function now follows straightforwardly:\QUESTION{how do we get the cosh term? its not a sum of exponentials, its a product.}
\[
    \begin{aligned}
        Z_N & = (Z_1)^N = (e^{-\beta \mathcal{H}^{(mf)}(\sigma_i)})^N
        = e^{-\beta J \frac{Nz}{2} m^2}
        \left[ e^{\beta \sum_{\sigma_i = \pm 1} \left( Jzm + H \right)\sigma_i}\right]^N \\
            & = e^{-\beta J \frac{Nz}{2} m^2}
        \prod_{\sigma_i = \pm 1}
        \left[ e^{\beta \left( Jzm + H \right)\sigma_i}\right]^N
        = e^{-\beta J \frac{Nz}{2} m^2} (2 \cosh(\beta(H+Jzm)))^N.
    \end{aligned}
\]
We have thus obtained the mean-field expression for the partition function.
It is worth noting that, although the approximation fails in \(d=1\) and is only qualitatively accurate in \(d=2\), it becomes exact for \(d \geq 4\). This behaviour is consistent with the Mermin--Wagner theorem, which forbids spontaneous symmetry breaking in low spatial dimensions.

\paragraph{Magnetization and self–consistency.}
We now aim to obtain an explicit expression for the order parameter of the system. Using the relation between the magnetization \(m\) and the Helmholtz free energy, we begin by computing the latter:
\[
    \begin{aligned}
        F & = -\frac{1}{\beta}\log Z_N
        = -\frac{1}{\beta}\left[-\beta J\frac{Nz}{2}m^2 + N\log\!\left(2\cosh(\beta(H+Jzm))\right)\right] \\
          & = J\frac{Nz}{2}m^2 - \frac{N}{\beta}\log\!\left(2\cosh(\beta(H+Jzm))\right).
    \end{aligned}
\]
Taking the derivative with respect to the magnetic field, we obtain the magnetization:
\[
    \begin{aligned}
        m & = -\frac{1}{N}\frac{\partial F}{\partial H}
        = -\frac{1}{\beta}\frac{\partial}{\partial H}
        \log(2\cosh(\beta(H+Jzm)))                                           \\
          & = -\frac{2\sinh(\beta(H+Jzm))\,\beta}{2\beta\cosh(\beta(H+Jzm))}
        = \tanh(\beta(H+Jzm)).
    \end{aligned}
\]
This equation contains \(m\) on both sides and therefore constitutes a \textit{self–consistency relation}. Such relations are typical of mean–field treatments and express the fact that the order parameter must be compatible with the field it generates.

Although the equation cannot be solved analytically, it already reveals important physical information. Since the right–hand side is monotonic, for \(H>0\) we find \(m>0\), and for \(H<0\) we find \(m<0\). Let us therefore focus on the case \(H=0\):
\[
    \begin{aligned}
        m & = \tanh(\beta J z m) = \tanh\!\left(\frac{T_c}{T} m\right) = \tanh(x), \\
        y & = \frac{T}{T_c} x = m = \tanh(x), \qquad T_c = \frac{J z}{k_B}.
    \end{aligned}
\]
This form makes the role of temperature explicit: it controls the slope of the straight line that must intersect the curve \(y=\tanh(x)\).
\begin{figure}[H]
    \begin{minipage}{0.6\textwidth}
        \centering
        \begin{tikzpicture}[scale=1.3]

            \draw[->] (-3.2,0) -- (3.2,0) node[right] {$x$};
            \draw[->] (0,-2) -- (0,2) node[above] {$y$};

            \draw[thick,red,domain=-3:3,samples=200]
            plot (\x,{tanh(\x)}) node[below] {$\tanh(x)$};

            \draw[gray] (1.6,1.6) -- (-1.6,-1.6)
            node[below] {\small $y=x$};

            \draw[blue,thick,dashed] (-1,-1.6) -- (1,1.6)
            node[above] {\small $T>T_c$};

            \draw[green!60!black,thick,dashed] (-3,-1.6) -- (3,1.6)
            node[above] {\small $T<T_c$};

            \draw[dashed] (1.8,0) -- (1.8,0.859);
            \draw[dashed] (-1.8,0) -- (-1.8,-0.859);

            \filldraw[green!60!black] (1.8,0) circle (1.5pt) node[below] {\small $m_0$};
            \filldraw[green!60!black] (-1.8,-0) circle (1.5pt) node[above] {\small $-m_0$};
            \filldraw[green!60!black] (1.8,0.95) circle (1.5pt);
            \filldraw[green!60!black] (-1.8,-0.95) circle (1.5pt);

            \filldraw[blue] (0,0) circle (1.5pt) node[above left] {\small $m=0$};
        \end{tikzpicture}
    \end{minipage}
    \hfill
    \begin{minipage}{0.35\textwidth}
        The graphical solution shows that for \(T > T_c\) the only intersection is at the origin, yielding \(m=0\): this corresponds to the \textbf{paramagnetic phase}. For \(T < T_c\), instead, the line intersects the curve at two symmetric non-zero points, corresponding to two stable ordered states with opposite magnetization: this is the \textbf{ferromagnetic phase}.
    \end{minipage}
\end{figure}

\subsection{Spontaneous Symmetry Breaking}

As we have established, the Ising Hamiltonian is symmetric under a global \(\mathbb{Z}_2 = \{\mathbb{I}, g\}\) transformation. However, this invariance of the Hamiltonian does not imply that the thermodynamic state of the system remains symmetric. We have observed that in the paramagnetic phase, the magnetization transforms as:
\[
    M \xrightarrow{\sigma_i \to -\sigma_i} -M, \quad \text{with } M=-M=0.
\]
Here, the symmetry is respected. In contrast, in the ferromagnetic state, the net magnetization is non-zero and thus is not invariant under \(\mathbb{Z}_2\). This phenomenon is known as \textit{spontaneous symmetry breaking} (SSB).

At lower temperatures, the system enters an ordered phase, and the effective symmetries are reduced to a subgroup \(G_0 \subset G\) of the original symmetry group. Let the order parameter depend on an observable \(\phi\) that is not invariant under the transformations of \(G\). If the thermal average behaves as follows:
\[
    \Phi = \langle \phi \rangle =
    \begin{dcases}
        0,                & \text{if } T \geq T_c, \\
        \Phi_0(T) \neq 0, & \text{if } T < T_c,
    \end{dcases}
\]
then we say \textit{the symmetry is spontaneously broken}. The magnetization serves as a perfect example of such an order parameter. It is important to note that while every instance of SSB implies the existence of a Phase Transition (PT), not all Phase Transitions are accompanied by SSB.

\paragraph{Correlation.}
Another quantity worthy of analysis is the \textit{correlation} (or covariance), which describes how spins influence each other over large distances. Intuitively, we expect the correlation to decrease as the distance increases, but the specific mode of this decay offers deep physical insights. The correlation function between two spins is defined as:
\[
    G_{ij} = \langle \sigma_i \sigma_j \rangle - \langle \sigma_i \rangle \langle \sigma_j \rangle = \langle \sigma_i \sigma_j \rangle -m^2,
\]
assuming translational invariance where \(\langle \sigma_i \rangle = \langle \sigma_j \rangle = m\). Letting \(r = \vert i-j \vert \) be the distance, the asymptotic behavior for large \(r\) is given by:\TODO{plot the correlation}
\begin{equation}
    G(r) = \begin{dcases}
        e^{-\tfrac{r}{\xi}},              & \text{ if }  T\neq T_c; \\
        \left( r^{d-2-\eta} \right)^{-1}, & \text{ if }  T=T_c.     \\
    \end{dcases}
    \label{eq:correlation_function}
\end{equation}
For \(T \neq T_c\), the correlation \(G(r)\) remains significantly large only for \(r < \xi\) and becomes negligible for \(r > \xi\). The parameter \(\xi\) is called the \textbf{correlation length}, representing the typical scale of fluctuations or the size of the regions within which spins are strongly correlated.

Crucially, we observe that \(\xi \to \infty\) as \(T \to T_c\). Physically, this means that as the critical temperature is approached, distant spins become increasingly correlated. Exactly at \(T=T_c\), the correlation length diverges, and the system exhibits long-range order, resulting in a power-law decay for \(G(r)\) rather than an exponential one.

\subsection{Critical Exponents}

We now investigate the behavior of the system as \(T \to T_c\) to characterize the properties of the Phase Transition. The strategy is to perform a Taylor expansion of \(\tanh(x)\). First, let us define a reduced temperature variable \(t\) (representing an infinitesimal deviation):
\begin{equation}
    t = \frac{T_c - T}{T_c} = 1-\frac{T}{T_c} \ll 1.
    \label{eq:reduced_temperature}
\end{equation}
From this, we can write the inverse temperature ratio as:
\[
    \frac{T_c}{T} = (1-t)^{-1} \sim 1 + t.
\]
Recall the mean-field equation involving the magnetization \(m\). We can make \(m\) explicit inside the argument of the hyperbolic tangent, or equivalently work with the inverse. Using the relation \(\tanh^{-1}(m) = \frac{T_c}{T} m\), and substituting our expression for \(T_c/T\):
\[
    \tanh^{-1}(m) = (1+t)m.
\]
Next, we Taylor expand the inverse hyperbolic tangent in powers of \(m\) (since \(m\) is small near \(T_c\)):
\[
    \tanh^{-1}(m) \sim m + \frac{m^3}{3} = (1+t)m \implies \frac{m^3}{3} \approx tm \implies m^2 = 3t.
\]
We have thus found how the magnetization scales in proximity to the Phase Transition:
\[
    m(T \to T_c) \sim t^{\tfrac12}, \quad \implies \beta=\frac{1}{2}.
\]
The reduced temperature \(t\) allows us to quantify the rapidity of the transition. In terms of the absolute temperature difference, we found:
\[
    m(T \to T_c) \sim \vert T - T_c \vert^{\beta = \tfrac12}.
\]

This exponent is one of several universal parameters defined to monitor the rate of change (scaling) of thermodynamic variables near a phase transition. These are called \textbf{critical exponents}. Formally, a critical exponent \(\lambda\) is associated with a variable \(f(t)\) as follows:
\begin{equation}
    \lambda = \lim_{t \to 0} \frac{\log(f(t))}{\log(t)} \longrightarrow f(t \to 0) = g(t)\vert t \vert^{\lambda}, \quad \text{where } g(0) \neq 0.
    \label{eq:critical_exponent_definition}
\end{equation}

These exponents characterize the singular behaviour of various thermodynamic quantities as the system approaches the critical point.
We typically consider six of these standard exponents:
\begin{itemize}
    \item \(\alpha\) for \textbf{specific heat}: \(C_{H=0} \sim \vert t \vert^{-\alpha}\);
    \item \(\beta\) for \textbf{order parameter} (magnetization): \(\phi \sim \vert t \vert^{\beta}\);
    \item \(\gamma\) for \textbf{susceptibility}: \(\chi_{H=0} \sim \vert t \vert^{-\gamma}\);
    \item \(\delta\) for \textbf{external field} (at the critical isotherm \(T=T_c\)): \(H \sim \mathrm{sgn}(\phi)\vert \phi \vert^{\delta}\);
    \item \(\nu\) for \textbf{correlation length}: \(\xi \sim \vert t \vert^{-\nu}\);
    \item \(\eta\) for \textbf{anomalous dimension} (at \(T=T_c\)): \(G(r) \sim \frac{1}{r^{d-2+\eta}}\).
\end{itemize}

\paragraph{Scaling Hypothesis.}
When the system undergoes a Phase Transition (PT), correlations spread throughout the nodes. Once the PT is completed, the system settles into a single thermodynamic phase. However, approaching the critical point, one can recognize fluctuations where different local states effectively coexist. During a continuous PT, the \textbf{correlation length} (or \textit{scale length}) diverges to infinity, until the entire system becomes correlated (in the Ising model, this corresponds to macroscopic magnetic ordering). At this precise moment, the system is said to be \textbf{scale invariant}. Conversely, as long as \(T \neq T_c\), the system is said to be \textit{holding a scale} (characterized by finite \(\xi\)), allowing us to distinguish the thermodynamic phases.

\begin{theorem}
    At a critical point during a PT, the system becomes scale invariant (this forms the basis of \textbf{Widom's hypothesis}). Consequently, the singular part of the free energy must be a homogeneous function of the reduced temperature \(t\) and the external field \(H\), respecting the scaling relation:
    \begin{equation}
        F(\lambda^a t,\, \lambda^b H) = \lambda F(t,\,H),
        \label{eq:scaling_hypothesis}
    \end{equation}
    for some scaling parameters \(a\) and \(b\).
\end{theorem}

From this hypothesis, we can compute the relations connecting the scaling parameters \(a\) and \(b\) with our critical exponents:
\[
    \begin{aligned}
        \alpha & = 2 - \frac{1}{a},\quad &  & \beta = \frac{1-b}{a},  \\
        \gamma & = \frac{2b-1}{a},\quad  &  & \delta = \frac{b}{1-b}, \\
        \nu    & = \frac{1}{da},\quad    &  & \eta = 2-d(2b-1).
    \end{aligned}
\]
Finally, it is useful to derive the \textit{scaling laws} (identities connecting the critical exponents), which act as a consistency check:
\begin{equation}
    \begin{dcases}
        (2 -\eta) \nu = \gamma,         \\
        \alpha + \beta(1 + \delta) = 2, \\
        d \nu = 2 - \alpha,             \\
        \alpha + 2\beta + \gamma = 2.
    \end{dcases}
    \label{eq:scaling_relations}
\end{equation}

\paragraph{Universality Classes.}
Due to scale invariance at the critical point, systems with different Hamiltonians and distinct microscopic descriptions might display the exact same type of PT. Microscopically, these systems may appear completely unrelated; however, as they approach the PT, their macroscopic behavior coincides. This implies that the numerical values of the six exponents \(\alpha,\,\beta,\,\gamma,\,\delta,\,\nu,\,\eta\) are identical across these systems.

We can thus classify PTs into \textbf{universality classes}. Membership in a class does not depend on the explicit form of the Hamiltonian or the specific details of the interactions, but only upon:
\begin{itemize}
    \item the \textit{dimension} of the physical space \(d=1,\,2,\,3\dots\);
    \item the \textit{symmetry group} \(G\) of the Hamiltonian;
    \item the \textit{residual symmetry subgroup} \(G_0\) in the \textit{broken phase} after the Spontaneous Symmetry Breaking (SSB).
\end{itemize}
If these three factors coincide, the Hamiltonians exhibit the same phase transition behavior and belong to the same universality class, characterized by a unique set of critical exponents.

\begin{remark}
    In \(d=1\) there is no finite-temperature PT because \(T_c \to 0\). Approaching \(T_c\) from above implies \(T \to 0\), and "crossing" it would physically imply negative temperatures (which are not accessible in equilibrium). Thus, the standard critical exponents are not well-defined for the 1D case.
\end{remark}