\section{Perturbative Expansion}

The free theory corresponds to a gaussian path integral, which is exactly solvable. With interactions, one is often unable to compute exactly the path integral, and one must resort to some sort of approximation. The simplest one is the perturbative expansion around a free theory, which consists in expanding the solution in power series of the coupling constants that parametrize the interactions. If the couplings are small enough, the perturbative expansion might give a good approximation of the solution.

We describe the perturbative expansion taking as a guiding example the \textbf{anharmonic oscillator}
\[
    S[x] = \int \d{t} \left( \frac{m}{2} \dot{x}^2 - \frac{m\omega^2}{2} x^2 -\frac{g}{3!} x^3 - \frac{\lambda}{4!} x^4 \right),
\]
where if the coupling constants \(g\) and \(\lambda\) vanish, the theory is exactly solvable. Thus, one may try to include perturbatively the corrections that arise when \(g\) and \(\lambda\) are small enough. It is convenient to split the action as the sum of two terms, a free part \(S_0\) which is exactly solvable and an interacting part \(S_{int}\)
\[
    \begin{aligned}
        S[x]       & = S_0[x] + S_{int}[x],                                                       \\
        S_0[x]     & = \int \d{t} \left( \frac{m}{2} \dot{x}^2 - \frac{m\omega^2}{2} x^2 \right), \\
        S_{int}[x] & = \int \d{t} \left( -\frac{g}{3!} x^3 - \frac{\lambda}{4!} x^4 \right).
    \end{aligned}
\]
The perturbative expansion is easily generated in the path integral setup. Including a source term, one expands in a Taylor series the exponential of the interaction term
\[
    \begin{aligned}
        Z[J] & = \int \mathrm{D}x\, e^{\frac{i}{\hbar}\left(S[x]+\int \d{t}Jx\right)} = \int \mathrm{D}x\, e^{\frac{i}{\hbar}S_{int}[x]}e^{\frac{i}{\hbar}\left(S_{0}[x]+\int \d{t}Jx\right)} \\
             & = \int \mathrm{D}x\, \left[ \sum_{n=0}^{\infty} \frac{1}{n!} \left(\frac{i}{\hbar}S_{int}[x]\right)^n \right] e^{\frac{i}{\hbar}\left(S_0[x]+\int \d{t}J x\right)}.
    \end{aligned}
\]
We can keep terms until we are satisfied with the resolution (depending on the entity of \(g\) and \(\lambda\)). Written in the last form, one proceeds in computing it term by term with the use of the Wick’s theorem. It can be written also in the form
\[
    Z[J] = \langle e^{\frac{i}{\hbar} S_{int}[x]} \rangle_{U,0,J},
\]
where the subscripts \(U,\,0,\,J\) denote unnormalized averaging \((U)\) in the free theory \((0)\) with an arbitrary source \((J)\). This expression is sometimes called the \textbf{“Dyson formula”}. It generates the perturbative expansion which can be depicted with \textit{Feynman diagrams}, as we shall see.

An alternative way of writing the perturbative series is the following one
\[
    \begin{aligned}
        Z[J] & = \int \mathrm{D}x\, e^{\frac{i}{\hbar}S_{int}[x]}e^{\frac{i}{\hbar}\left(S_{0}[x]+\int \d{t}Jx\right)}                                                                                                                                                                               \\
             & = \exp\left( \frac{i}{\hbar} S_{int}\left[ \frac{\hbar}{i} \frac{\delta}{\delta J} \right] \right) \int \mathrm{D}x\, e^{\frac{i}{\hbar}\left(S_0[x]+\int \d{t}J x\right)} = \exp\left( \frac{i}{\hbar} S_{int}\left[ \frac{\hbar}{i} \frac{\delta}{\delta J} \right] \right) Z_0[J],
    \end{aligned}
\]
where \(Z_0[J]\) is the generating functional of the free theory. This expression is often more convenient to work with, since it reduces the problem to computing functional derivatives of the known free generating functional. It presents the solution as a (quite complicated) differential operator acting on the functional of the free theory \(Z_0[J]\). In particular, all vacuum diagrams are generated by
\[
    Z[0] = \int \mathrm{D}x\, e^{\frac{i}{\hbar}S[x]} = \exp\left( \frac{i}{\hbar} S_{int}\left[ \frac{\hbar}{i} \frac{\delta}{\delta J} \right] \right) Z_0[J] \Big\vert_{J=0}.
\]
The perturbative expansion can be represented using Feynman diagrams. These are constructed by expanding the interaction term in the path integral and applying Wick’s theorem to compute the correlation functions within the free theory. In these diagrams, vertices, represented as dots, correspond to the interaction potentials and involve a coupling constant multiplied by quantum variables. These variables are paired in all possible combinations using free propagators, which are graphically depicted as lines.

This construction is illustrated below through the example of vacuum diagrams for the anharmonic oscillator.

\subsection{Vacuum Diagrams}

As an example, we compute perturbatively the corrections to the ground state energy of the harmonic oscillator due to the \textbf{anharmonic potential} terms. It is often the case that one computes using the euclidean version of the theory and performs the inverse Wick rotation at the very end to obtain the final result in minkowskian time.

Thus, let us consider the euclidean generating functional and action for the \textbf{anharmonic oscillator}
\[
    \begin{aligned}
        Z_E[J] & = \int \mathrm{D}x\, e^{-\frac{1}{\hbar}\left(S_E[x]-\int \d{\tau} J x\right)},                                                                                          \\
        S_E[x] & = \lim_{\beta \to \infty} \int_{-\beta/2}^{\beta/2} \d{\tau} \left( \frac{m}{2} \dot{x}^2 + \frac{m\omega^2}{2} x^2 + \frac{g}{3!} x^3 + \frac{\lambda}{4!} x^4 \right).
    \end{aligned}
\]
We want to compute corrections to the ground state energy, which can be obtained from the vacuum diagrams, which correspond to \(Z_E[0]\). Using the perturbative expansion, we have
\[
    \begin{aligned}
        Z_E[0] = \int \mathrm{D}x\, e^{-\frac{1}{\hbar}S_{E}[x]} = \langle 1 \rangle_{U} = \lim_{\beta \to \infty} \bra{0} e^{-\beta \hat{H}} \ket{0} = \left\langle e^{-\frac{1}{\hbar} S_{E, int}[x]} \right\rangle_{U,0} = \lim_{\beta \to \infty} e^{-\beta E_0^{(0)}+ \Delta E_0},
    \end{aligned}
\]
where the exact energy \(E_0\) of the ground state \(\ket{0}\) of the anharmonic oscillators differs from the ground state energy of the harmonic oscillator \(E_0^{(0)}\) by the term \(\Delta E_0\) due to the anharmonic potential (here we have the contributions from interaction terms). The correction \(\Delta E_0\) can be computed perturbatively, considering the first non-vanishing corrections to exemplify the perturbative expansion with path integrals and the use of Feynman diagrams.

When we take \(\beta \to \infty\), we are projecting onto the ground state, since we assume that the spectrum of the Hamiltonian is bounded from below. Thus, the euclidean time evolution operator \(e^{-\beta \hat{H}}\) suppresses all contributions from excited states exponentially fast as \(\beta\) increases. Then we apply the perturbative expansion in the interaction term (as we did in Minkowskian time in the previous section), which gives us an unnormalized average in the free theory. Now we can recognize that this average corresponds to the vacuum amplitude of the free theory multiplied by corrections due to the interactions.

We can continue the computation for the interaction terms in the correlation function by considering separately the two terms (by setting each one to zero and effectively \textit{turning off} one interaction at a time). Let us look first at the case with \(g=0\) and focus on the first correction in \(\lambda\) for the \textbf{quartic interaction}:
\[
    \begin{aligned}
        Z_E[0] & = \langle 1 \rangle_U = \left\langle \sum_{n=0}^{\infty} \frac{1}{n!} S_{E,\,int}[x]^n \right\rangle_{U,0} = \langle 1 \rangle_{U,0} -\frac{\lambda}{4!} \int_{-\beta/2}^{\beta/2} \d{\tau} \langle x^4(\tau) \rangle_{U,0} + \cdots                 \\
               & = \langle 1 \rangle_{U,0} \left[ 1 -\frac{\lambda}{4!} \int_{-\beta/2}^{\beta/2} \d{\tau} \langle x^4(\tau) \rangle_{U,0} +\cdots \right] = \langle 1 \rangle_{U,0} \left[ 1 -\frac{\lambda}{4!} \left( 3\times \feynEight \right) + \cdots \right].
    \end{aligned}
\]
In the last line, we have used Wick contractions to calculate normalized correlation functions in the free theory, and then introduced a graphical representation in terms of \textbf{Feynman diagrams}. In this graphical representation, a line denotes a propagator that joins two points in time, while vertices arising from the interactions are denoted by dots. The term we obtained contains just one vertex where four lines can enter or exit, corresponding to the power four of the dynamical variable \(x(\tau)\) associated to the interaction under consideration.

Recalling the euclidean propagator calculated in eq. \eqref{eq:euclidean_green_function_harmonic_oscillator}
\[
    G_E(\tau - \tau^{\prime}) = \langle x(\tau) x(\tau^{\prime}) \rangle_0 = \frac{1}{2\omega} e^{-\omega \vert \tau - \tau^{\prime} \vert} = \feynLine
\]
where this is the \textbf{Feynman Line} associated to the two point correlation function; we can compute the value of the previous diagram, considering that we have four fields at the same time \(\tau\). Thus, we have to consider all possible Wick contractions, which give three identical contributions (we have \(x(\tau)^4\) not \(x_1(\tau)x_2(\tau)\cdots\) so the fields are identical), each corresponding to a pair of propagators that start and end at the same time \(\tau\). Therefore, we have
\[
    DIAGRAMS \quad SUM
\]
So that we understand why we wrote \(3 \times \feynEight\) in the previous expression. Now, we can compute the value of the diagram \(\feynEight\) understanding it as a loop with two propagators that start and end at the same time:
\[
    \feynEight = \int_{-\beta/2}^{\beta/2} \d{\tau} \, G_E(\tau,\tau)^2 = \int_{-\beta/2}^{\beta/2} \d{\tau} \, \left( \frac{1}{2\omega} \right)^2 = \frac{\beta}{4\omega^2}.
\]
Thus, up to this order (first term) in perturbation theory, we have\footnote{This computation relies on the boundaries conditions we have set: with \(\beta \to  \infty\) we are projected on the ground state, and the propagator is computed with this precise Green function, while different boundary conditions would lead to different propagators and thus different results.}
\[
    Z_E[0] = \langle 1 \rangle_{U,0} \left[ 1 - \frac{\lambda}{4!} \left( 3 \times \frac{\beta}{4\omega^2} \right) + \cdots \right] = \langle 1 \rangle_{U,0} \exp\left( -\beta \frac{\lambda}{32\omega^2} + \cdots \right),
\]
so that we can read the correction to the ground state energy due to the quartic interaction
\[
    \Delta E_0 = \frac{1}{32} \frac{\lambda}{\omega^2}.
\]

Similarly, one may consider the case with \(g \neq 0\) and \(\lambda = 0\). The first non-vanishing correction in the \textbf{cubic interaction} arises from:
\[
    \begin{aligned}
        Z_E[0] & = \langle 1 \rangle_U = \left\langle \left( 1- S_{E,\,int} + \frac{1}{2}S_{E,\,int}^2 + \cdots \right) \right\rangle_{U,0}                                                                                                                                                  \\
               & = \langle 1 \rangle_{U,0} + \frac{g}{3!} \int_{-\beta/2}^{\beta/2} \d{\tau} \langle x^3(\tau)\rangle_{U,0} + \frac{g^2}{2(3!)^2} \int_{-\beta/2}^{\beta/2} \d{\tau} \int_{-\beta/2}^{\beta/2} \d{\tau^{\prime}} \langle x^3(\tau) x^3(\tau^{\prime}) \rangle_{U,0} + \cdots \\
               & = \langle 1 \rangle_{U,0} \left[ 1 + 0 + \frac{g^2}{2(3!)^2}\left((3!)\times \feynSunset + (3^2)\times \feynDumbbell \right) + \cdots \right].
    \end{aligned}
\]
The first correction vanishes because there is no way to contract three fields at the same time in pairs (from Wick's theorem). The second correction is represented by a six-point correlation function, which gives two types of contributions: we have three fields at time \(\tau\) and three fields at time \(\tau^{\prime}\), which can be contracted in two different ways.
\[
    DIAGRAMS \quad SUM
\]
The first one has two vertices and three propagators connecting them (in \(3\times 2\times 1\) possible permutations), while the second one has two vertices connected by a single propagator (the two vertices can be chosen from any of the present, so \(3\times 3\) possibilities), with each vertex having a loop attached to it. We can check the combinatorial factors by counting the number of Wick contractions that give rise to each diagram: \(6+9 = 15\), which is indeed the number of ways to contract six fields in pairs.

Thus we have found two types of diagrams: one is the \textbf{sunset diagram} \(\feynSunset\) where two vertices are connected by three propagators, while the other one is the \textbf{dumbbell diagram} \(\feynDumbbell\) where two vertices are connected by a single propagator and each vertex has a loop attached to it. The combinatorial factors arise from the number of Wick contractions that give rise to each diagram. We can compute their values as follows. For the sunset diagram, we have\footnote{We do not compute the limit for \(\beta \to \infty\) yet, since we are just interested in the value of the diagram itself. We will take the limit at the very end to extract the ground state energy correction after inserting these results into the expression for \(Z_E[0]\).}
\[
    \begin{aligned}
        \feynSunset & = \int_{-\beta/2}^{\beta/2} \d{\tau} \int_{-\beta/2}^{\beta/2} \d{\tau^{\prime}} \, G_E(\tau,\tau^{\prime})^3 = \int_{-\beta/2}^{\beta/2} \d{\tau} \int_{-\beta/2}^{\beta/2} \d{\tau^{\prime}} \, \left( \frac{1}{2\omega} e^{-\omega \vert \tau - \tau^{\prime} \vert} \right)^3 \\
                    & = \frac{1}{8\omega^3} \int_{-\beta/2}^{\beta/2} \d{\tau} \int_{-\infty}^{\infty} \d{\sigma} \, e^{-3\omega \sigma} = \frac{\beta}{8\omega^3} 2 \int_{0}^{\infty} \d{\sigma} \, e^{-3\omega \sigma}                                                                                \\
                    & = \frac{\beta}{8\omega^3} 2 \left. \frac{e^{-3\omega \sigma}}{-3\omega} \right|_0^\infty = \frac{\beta}{8\omega^3}\frac{2}{3\omega} = \frac{\beta}{12\omega^4},
    \end{aligned}
\]
while for the dumbbell diagram, we have
\[
    \begin{aligned}
        \feynDumbbell & = \int_{-\beta/2}^{\beta/2} \d{\tau} \int_{-\beta/2}^{\beta/2} \d{\tau^{\prime}} \, G_E(\tau-\tau) G_E(\tau - \tau^{\prime}) G_E(\tau^{\prime} - \tau^{\prime})                                      \\
                      & = \int_{-\beta/2}^{\beta/2} \d{\tau} \int_{-\beta/2}^{\beta/2} \d{\tau^{\prime}} \, \left( \frac{1}{2\omega} \right)^2 \left( \frac{1}{2\omega} e^{-\omega \vert \tau - \tau^{\prime} \vert} \right) \\
                      & = \frac{\beta}{4\omega^2} 2 \int_{0}^{\infty} \d{\sigma} \, \frac{1}{2\omega} e^{-\omega \sigma} = \frac{\beta}{4\omega^2} 2 \left. \frac{e^{-\omega \sigma}}{-\omega} \right|_0^\infty              \\
                      & = \frac{\beta}{8\omega^3}\frac{2}{\omega} = \frac{\beta^2}{4\omega^4}.
    \end{aligned}
\]
Now, we can insert these results into the expression for \(Z_E[0]\) to obtain
\[
    Z_E[0] = \langle 1 \rangle_{U,0} \left[ 1 + \frac{g^2}{2(3!)^2} \left( (3!) \times \frac{\beta}{12\omega^4} + (3^2) \times \frac{\beta^2}{4\omega^4} \right) + \cdots \right] = \langle 1 \rangle_{U,0} \exp\left( \beta \frac{11}{8(3!)^2} \frac{g^2}{\omega^4} + \cdots \right),
\]
finding the entity of the correction to the ground state energy due to the cubic interaction
\[
    \Delta E_0 = - \frac{11}{288} \frac{g^2}{\omega^4}.
\]

\subsection{Other Correlators and Feynman Diagrams}
In a similar way, one computes the perturbative expansion of other correlation functions, considering that the vacuum diagrams correspond to unnormalized 0-point function, relating to the ground state energy. We start from the vacume, something happens during the evolution, and we return to the vacuum.

We can treat the two point correlation function in a similar way. We have two particles, one in the far past and one in the far future, which interacts in some way (for example the anharmonic potential seen before) during their evolution. The two point correlation function is given by
\[
    \begin{aligned}
        \langle x(t_1) x(t_2) \rangle & = \frac{1}{Z} \int \mathrm{D}x\, x(t_1) x(t_2) e^{\frac{i}{\hbar}S[x]} = \left\langle x(t_1) x(t_2) e^{\frac{i}{\hbar} S_{int}[x]} \right\rangle_{0}              \\
                                      & = \left\langle x(t_1) x(t_2) \left[ 1 + \frac{i}{\hbar} S_{int}[x] + \frac{1}{2!} \left( \frac{i}{\hbar} S_{int}[x] \right)^2 + \cdots \right] \right\rangle_{0}.
    \end{aligned}
\]
We can interpret as follows: we have two external points at times \(t_1\) and \(t_2\) where particles are created/annihilated, and we have to consider all possible interactions that may happen during their evolution. Using Wick contractions, we can compute the perturbative expansion of this correlation function in the free theory. For the case of a cubic interaction, \(S_{int} = -\frac{g}{3!}\int\d{t}x(t)^3\), it leads to the following diagrammatic expansion up to second order in perturbation theory:
\[
    DIAGRAMS
\]
its like studying a 8 point function but with 2 external points fixed.
The first diagram corresponds to the free propagator between times \(t_1\) and \(t_2\). The second diagram represents the first-order correction due to a single interaction vertex, where the two external points are connected through a loop. The third and fourth diagrams represent second-order corrections, involving two interaction vertices. The third diagram shows two vertices connected by three propagators, while the fourth diagram has two vertices connected by a single propagator with loops attached to each vertex. This exemplifies how Feynman diagrams arise naturally in the perturbative expansion of correlation functions in quantum field theory.

Let us describe graphically the corrections that must be computed for calculating perturbatively the 4-point function (in a QFT context, it is linked to the scattering of 2 incoming particles to 2 outgoing particles)
\[
    \langle x(t_1) x(t_2) x(t_3) x(t_4) \rangle
\]
where one may keep in mind that setting \(t_1,\,t_2 \to -\infty\) describes incoming states while \(t_3,\,t_4 \to +\infty\) describes outgoing states. We have
\[
    \begin{aligned}
        \langle x(t_1) x(t_2) x(t_3) x(t_4) \rangle & = \frac{1}{Z} \int \mathrm{D}x\, x(t_1) x(t_2) x(t_3) x(t_4) e^{\frac{i}{\hbar}S[x]} = \left\langle x(t_1) x(t_2) x(t_3) x(t_4) e^{\frac{i}{\hbar} S_{int}[x]} \right\rangle_{0} \\
                                                    & = \left\langle x(t_1) x(t_2) x(t_3) x(t_4) \left[ 1 + \frac{i}{\hbar} S_{int}[x] + \frac{1}{2!} \left( \frac{i}{\hbar} S_{int}[x] \right)^2 + \cdots \right] \right\rangle_{0}.
    \end{aligned}
\]

For the case of a cubic interaction, \(S_{int} = -\frac{g}{3!}\int\d{t}x(t)^3\), it leads to the following diagrammatic expansion which is obtained by the systematic use of Wick contractions:\TODO{Modify last diagram in first row, it needs 4 external points.}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{img/diagrammatic_expansion_cubic_interaction.png}
    \caption{Diagrammatic expansion of the 4-point function for a cubic interaction up to second order in perturbation theory.}
    \label{fig:diagrammatic_expansion_cubic_interaction}
\end{figure}

One notices disconnected, connected, and 1PI diagrams, which play a significant role in QFT (1PI diagrams are those diagrams that remain connected after cutting any single internal line). This exemplifies the emergence of Feynman diagrams in describing the perturbative expansion.

Nobody knows what happens during the interaction, virtually anything can happen, but we can sum over all the possibilities using the path integral formalism and Wick’s theorem.

Here ends the treatment for the \textbf{bosonic path integral}: we saw that this formalism aplies naturally on the KG field and scalar fields in general, and we developed the perturbative expansion with Feynman diagrams. In the next section, we extend the path integral formalism to fermionic systems.

\section{Path Integrals for Fermions}

We now discuss how to extend the path integral method to fermionic systems. Fermions at the classical level can be described by \textbf{Grassmann variables}, also known as \textbf{anticommuting} numbers or fermionic variables. Grassmann variables allow us to define “classical” models whose quantization produces degrees of freedom that satisfy the Pauli exclusion principle.

The question is: how can we define a path integral for fermionic systems? The main difficulty arises from the anticommuting nature of fermionic variables, which makes the standard definition of the path integral inapplicable. There is no classical trajectory for fermions in the usual sense, since the ferionic nature of the particles vanishes in the classical limit \(\hbar \to 0\). To overcome this issue, we introduce Grassmann variables to describe fermionic degrees of freedom at the classical level.

We need to introduce a suitable Hamiltonian theory to deal with fermionic degrees of freedom, which has symmetric Poisson Brackets, in order to quantize them canonically obtaining a quantum theory based on \textit{anticommutators}.
This is why we call it a \textbf{pseudoclassical model}: it is not a classical model in the usual sense, but it is a formal construction that allows us to quantize fermionic degrees of freedom, and leads to the correct quantum theory based on Grassmann variables.
\[
    \left\{ \psi,\,\overline{\psi} \right\}_{C} \longrightarrow \left\{ \hat{\psi},\,\hat{\psi}^\dagger \right\} = i \hbar \dots .
\]
Models with Grassmann variables are often called “pseudoclassical”, as the spin at the classical level is just a formal construction (the value of any finite spin vanishes for \(\hbar \to  0\), and thus cannot be measured classically). In the following, we first exemplify the use of Grassmann variables in mechanical models. The method extends to field theories as well, so that a Dirac field can be treated classically with Grassmann variables. Then, we develop canonical quantization for mechanical models containing Grassmann variables.

At last, we derive a path integral representation of the transition amplitude for fermionic systems starting from its operatorial expression and using a suitable definition of fermionic coherent states.

\subsection{Grassmann Algebras}

A \(n\)-dimensional Grassmann algebra \(\mathcal{G}_n\) is generated by a set of generators \(\theta_i\) with \(i=1,\,\ldots,\,n\), which satisfy the anticommutation relations
\[
    \left\{ \theta_i,\,\theta_j \right\} = \theta_i \theta_j + \theta_j \theta_i = 0, \quad \forall i,\,j = 1,\,\ldots,\,n.
\]
From these relations, it follows that
\[
    \theta_i^2 = 0,
\]
for all \(i\). The elements of the Grassmann algebra are linear combinations of products of the generators, with complex coefficients. This suggests already at the classical level the essence of the Pauli exclusion principle, according to which one cannot put two identical fermions in the same quantum state. Physicists often call these generators anticommuting numbers.

We will now describe some properties of Grassmann algebras that will be useful in the following: functions of Grassmann variables, derivatives with respect to Grassmann variables, integration over Grassmann variables, and reality properties, with the aim of defining a path integral for fermionic systems.

\paragraph{Functions.}
One can multiply these generators and their products by real or complex numbers and form polynomials that are used to define functions of the Grassmann variables (i.e., the elements of the Grassmann algebra). For example, for \(n=1\), there is only one Grassmann variable \(\theta\). Then, an arbitrary function is given by
\[
    f(\theta) = f_0 + f_1 \theta,
\]
where \(f_0\) and \(f_1\) are taken to be either real or complex numbers, and higher power of theta vanish (we can factor a \(\theta^2 = 0\)). Similarly, for \(n=2\) one has
\[
    f(\theta_1,\,\theta_2) = f_0 + f_1 \theta_1 + f_2 \theta_2 + f_{3} \theta_1 \theta_2,
\]
and so on for higher dimensions. A term with \(\theta_2 \theta_1\) is not written as it is not independent of \(\theta_1 \theta_2\): \(\theta_2 \theta_1 = -\theta_1 \theta_2\). Terms with an even number of \(\theta\)’s are called Grassmann even (or equivalently: even, commuting, bosonic). Terms with an odd number of \(\theta\)’s are called \textit{Grassmann odd} (or equivalently: odd, anticommuting, fermionic). Generic functions are always defined in terms of their Taylor expansions, which contain a finite number of terms because of the Grassmann property. For example, the exponential function \(e^{\theta} \) means \(e^\theta = 1 + \theta\) because \(\theta^2 = 0\) as any other higher power.

\paragraph{Derivatives.}
Derivatives with respect to Grassmann variables are very simple. As any function can be at most linear with respect to any fixed Grassmann variable, its derivative is straightforward and one has to keep track just of signs. \textbf{Left derivatives} are defined by removing the variable from the left of its Taylor expansion: for example for the function \(f(\theta_1, \theta_2)\) given above
\[
    \frac{\partial_L}{\partial \theta_1} f(\theta_1, \theta_2) = f_1 + f_3 \theta_2,
\]
since \(\theta_1\) is removed from the left. Similarly, \textbf{right derivatives} are obtained by removing the variable from the right\footnote{Since before applying the derivative one has to anticommute the variables until the object of the derivation is in the last position on the right: if it is already there, no sign change occurs.}
\[
    \frac{\partial_R}{\partial \theta_1} f(\theta_1, \theta_2) = f_1 - f_3 \theta_2,
\]
where a minus sign emerges because one has first to commute \(\theta_1\) past \(\theta_2\). One can obtain the same minus sign by left derivatives on \(\theta_2\) using the function of the last example. Equivalently, introducing Grassmann increments \(\delta \theta\), one may write
\[
    \delta f = f(\theta + \delta \theta) - f(\theta) = \delta \theta \frac{\partial_L f}{\partial \theta} = \frac{\partial_R f}{\partial \theta} \delta \theta,
\]
which helps in keeping track of signs. If not specified otherwise, we use left derivatives and omit the corresponding subscript.

\paragraph{Integrals.}
Integration can be defined, according to \textbf{Berezin}, to be identical to differentiation
\[
    \int \d{\theta} = \frac{\partial_L}{\partial \theta}.
\]
This definition has the virtue of producing a \textbf{translational invariant}\footnote{Which, as we have precedently highlighted, is a property we should look for in order to define a consistent thery of integration for our path integrals (think about the previously discussed gaussian integrals).} measure:
\[
    \int \d{\theta} f(\theta + \eta) = \int \d{\theta + \eta} f(\theta + \eta) = \int \d{\tilde{\theta}} f(\tilde{\theta}),
\]
as the measure is translational invariant, \(\d{\theta} = \d{\tilde{\theta}}\) , and \(\tilde{\theta} = \theta + \eta\). This statement is easily proven by a direct calculation
\[
    \int \d{\theta} f(\theta + \eta) = \frac{\partial_L}{\partial \theta} \left( f_0 + f_1 (\theta + \eta) \right) = f_1 = \int \d{\tilde{\theta}} f(\tilde{\theta}),
\]
thus confirming the translational invariance of the measure, which is practically manifest and one of the main reasons for defining integration in this way.

\paragraph{Reality properties.}
Grassmann variables can be defined to be either real or complex. A real variable satisfies
\[
    \overline{\theta} = \theta,
\]
with the bar indicating complex conjugation. For products of Grassmann variables, the complex conjugate is defined to include an exchange of their position
\[
    \overline{\theta_1 \theta_2} = \overline{\theta}_2 \, \overline{\theta}_1.
\]
Thus, the complex conjugate of the product of two real variables is purely imaginary
\[
    \overline{\theta_1 \theta_2} = - \theta_1 \theta_2.
\]
It is the combination \(i \theta_1 \theta_2\) that is real, as the complex conjugate of the imaginary unit carries the additional minus sign to obtain a formally real object
\[
    \overline{i \theta_1 \theta_2} = -i \theta_2 \theta_1 = i \theta_1 \theta_2.
\]
Complex Grassmann variables \(\eta\) and \(\overline{\eta}\) can always be decomposed in terms of two real Grassmann variables \(\theta_1\) and \(\theta_2\) by setting
\[
    \eta = \frac{1}{\sqrt{2}} (\theta_1 + i \theta_2), \quad \overline{\eta} = \frac{1}{\sqrt{2}} (\theta_1 - i \theta_2).
\]
These definitions on the reality properties of the Grassmann variables are the ones that are the most useful for physical applications, since one requires that \textit{real variables become hermitian operators upon quantization}.

\paragraph{Gaussian integrals.}
This integrals are crucial in order to derive the Free theory, first step before moving to a perturbative one. Having defined integration over Grassmann variables, we consider in more detail the gaussian integration, which is at the core of fermionic path integrals. For the case of a single real Grassmann variable \(\theta\) the gaussian function is trivial, \(e^{-a \theta^2} = 1\) , since \(\theta^2=0\) as \(\theta\) anticommutes with itself. One needs at least two real Grassmann variables \(\theta_1\) and \(\theta_2\) to have a nontrivial exponential function with an exponent quadratic in Grassmann
\[
    e^{-a \theta_1 \theta_2} = 1 - a \theta_1 \theta_2,
\]
where \(a\) is either real or complex. With the above definitions, the corresponding “gaussian integral” is computed straightforwardly
\[
    \int \d{\theta_1} \d{\theta_2} e^{-a \theta_1 \theta_2} = \int \d{\theta_1} \d{\theta_2} (1 - a \theta_1 \theta_2) = \frac{\partial_L}{\partial \theta_1} \frac{\partial_L}{\partial \theta_2} (1 - a \theta_1 \theta_2) = a.
\]
Note that there is a precise sign defined by the chosen measure ordering, as \(\int \d{\theta_1} \d{\theta_2} = - \int \d{\theta_2} \d{\theta_1}\). Defining the antisimmmetric matrix
\[
    A = \begin{pmatrix}
        0  & a \\
        -a & 0
    \end{pmatrix}, \quad \det A = a^2,
\]
one may rewrite the previous integral as
\[
    \int \mathrm{d}^2 \theta \, e^{-\frac{1}{2} \theta_i A_{ij} \theta_j} = \int \d{\theta_1} \d{\theta_2} e^{-a \theta_1 \theta_2} = a = \sqrt{\det A}.
\]
The square root of the determinant of an antisymmetric matrix A is called the \textbf{Pfaffian}, and often indicated by \(\text{Pfaff}\, A\). Indeed, the determinant is always positive definite for real antisymmetric matrices, and its square root is well-defined (by analytic extensions, it is also well-defined for antisymmetric matrices with complex entries). It is easy to see that the above formula extends to an even number \(n = 2m\) of real Grassmann variables, so that one may write in general
\[
    \int \mathrm{d}^n \theta \, e^{-\frac{1}{2} \theta_i A_{ij} \theta_j} = \text{Pfaff}\, A = \sqrt{\det A},
\]
where \(A\) is a real antisymmetric \(n \times n\) matrix and \(\mathrm{d}^n \theta = \mathrm{d} \theta_1 \cdots \mathrm{d} \theta_n\). This formula is the fermionic counterpart of the bosonic gaussian integral seen before (where if one remember, the square root of the determinant of the matrix at the exponent was inverse: \((\det K)^{-1 / 2}\)), and it plays a crucial role in defining fermionic path integrals.
To prove this, one notices that with an orthogonal transformation it is possible to skew-diagonalize the antisymmetric matrix \(A_{ij}\) and put it in the form
\[
    \begin{pmatrix}
        0      & a_1    & 0      & 0      & \dots  & 0      & 0      \\
        -a_1   & 0      & 0      & 0      & \dots  & 0      & 0      \\
        0      & 0      & 0      & a_2    & \dots  & 0      & 0      \\
        0      & 0      & -a_2   & 0      & \dots  & 0      & 0      \\
        \vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
        0      & 0      & 0      & 0      & \dots  & 0      & a_m    \\
        0      & 0      & 0      & 0      & \dots  & -a_m   & 0
    \end{pmatrix}
\]
The orthogonal transformation leaves the integration measure invariant and thus one gets the above result with \((\det A)^{1 / 2} = a_1 \cdots a_m \). A cautionary note: to compute correctly the jacobian under a change of variables one should recall the definition of the integration in terms of derivatives (the Berezin integration), and thus find the inverse matrix with respect to the one associated with an analogous bosonic integral.

Similarly, one finds that gaussian integration over complex Grassmann variables \((\eta_i,\, \overline{\eta}_i)\) produce a determinant
\[
    \int \mathrm{d}^n\overline{\eta} \mathrm{d}^n\eta e^{-\overline{\eta}_i A_{ij} \eta_j} = \det A,
\]
where the measure is now deifined as \(\mathrm{d}^n\overline{\eta} \mathrm{d}^n\eta = \d{\eta_1}\d{\overline{\eta}_1} \cdots \d{\eta_n} \d{\overline{\eta}_n}\).

For applications to dynamical models and subsequent path integral quantization, it is useful to consider infinite dimensional Grassmann algebras (\(n \to \infty\)). Then, one may use Grassmann valued functions of time, i.e. \(\theta_i \to \theta(t)\). For different values of \(t\), one has different generators of the algebra, so that properties such as \(\theta^2(t) = 0\) and \(\theta(t) \theta(t') = - \theta(t') \theta(t)\) hold. They are used to introduce useful mechanical systems at the classical level, often named psudoclassical models, that upon quantization produce systems satisfying the Pauli exclusion principle and the Fermi-Dirac statistic.

\subsection{Pseudoclassical Model and Canonical Quantization}

We are going to exemplify the use of Grassmann variables in mechanical models. We will use the so called \textbf{fermionic oscillator}: if we remember the bosonic harmonic oscillator, we can define its fermionic counterpart by introducing Grassmann variables.

Classically, it is described by the function \(\psi(t)\) and its complex conjugate \(\overline{\psi}(t)\) that take values in a Grassmann algebra (\(t\) denotes the time). The Grassmann property implies generic relations like
\[
    \psi(t)^2 = 0, \quad \psi(t) \psi(t') = - \psi(t') \psi(t), \quad \dot{\psi}(t)^2 = 0, \quad \psi(t) \dot{\psi}(t) = - \dot{\psi}(t) \psi(t),
\]
and so on, where dots denote time derivatives, \(\dot{\psi} = \frac{\mathrm{d}}{\mathrm{d}t} \psi\). Note already at this stage, that \(\psi(t) \dot{\psi}(t)\) is not a total derivative. These relations can be used in extremizing the action, testing the presence of symmetries, and so on.

For the bosonic harmonic oscillator, we had the action
\[
    S[x,p] = \int \d{t} \left( p \dot{x} - \frac{1}{2} (p^2 + \omega^2 x^2) \right),
\]
which can be rewritten with complex variables derived via linear combinations of \(x\) and \(p\)
\[
    a = \frac{1}{\sqrt{2 \omega}} (\omega x + i p), \quad \overline{a} = \frac{1}{\sqrt{2 \omega}} (\omega x - i p),
\]
so that the action becomes
\[
    S[a,\,\overline{a}] = \int \d{t} \left( \frac{i}{2} (\overline{a} \dot{a} - \dot{\overline{a}} a) - \omega \overline{a} a \right).
\]\TODO{check expression of action in complex variables.}
Quantization of the complex variables (\(a, \overline{a}\)) gives rise to the annhilation/creation operators (\(\hat{a}, \hat{a}^\dagger\)) that satisfy the algebra \([\hat{a}, \hat{a}^\dagger] = \hbar\) (however we will use mostly \(\hbar = 1\)). They are used in the Fock construction of the Hilbert space of the harmonic oscillator, which is reviewed later on in sec. \ref{sec:coherent_states_fermions} when we consider coherent states.

To define the fermionic counterpart, we introduce two complex Grassmann-valued functions \(\psi(t)\) and \(\overline{\psi}(t)\), and write the action
\begin{equation}
    S[\psi,\,\overline{\psi}] = \int \d{t} \left( i \overline{\psi} \dot{\psi} - \omega \overline{\psi} \psi \right).
    \label{eq:fermionic_oscillator_action}
\end{equation}
This action is the fermionic counterpart of the bosonic harmonic oscillator action written in terms of complex variables. It is linear in time derivatives, as it must be for fermionic systems (if it were quadratic, the Grassmann property would imply that the action vanishes identically). As its bosonic counterpart, it is real.

Now if we compute the variation of the action with respect to \(\overline{\psi}\) and \(\psi\), we find the equations of motion
\[
    \delta S = 0 = \int \d{t} \left[ i \delta \overline{\psi} \left( i \dot{\psi} - \omega \psi\right) + \left(- i \dot{\overline{\psi}} - \omega \overline{\psi}\right) \delta \psi \right].
\]
Thus, the equations of motion are
\begin{equation}
    i \dot{\psi} - \omega \psi = 0, \quad - i \dot{\overline{\psi}} - \omega \overline{\psi} = 0,
    \label{eq:fermionic_oscillator_eom}
\end{equation}
and their solutions are easily found to be
\begin{equation}
    \psi(t) = \psi_0 e^{-i \omega t}, \quad \overline{\psi}(t) = \overline{\psi}_0 e^{i \omega t},
    \label{eq:fermionic_oscillator_solutions}
\end{equation}
where \(\psi_0\) and \(\overline{\psi}_0\) are Grassmann constants. This equation may be called the Dirac equation in a 0+1 dimensional spacetime, as one may rewrite it as \((\gamma^0 \partial_0 + m )\psi = 0\) with \(\gamma^0 = -i\), \(x^0 = t\), and the frequency \(\omega = m\) playing the role of the Dirac mass.

To proceed with canonical quantization, we compute the conjugate momenta
\begin{equation}
    \pi = \frac{\partial_L \mathcal{L}}{\partial \dot{\psi}} = - i \overline{\psi}, \quad \overline{\pi} = \frac{\partial_L \mathcal{L}}{\partial \dot{\overline{\psi}}} = 0.
    \label{eq:conjugate_momenta_fermionic_oscillator}
\end{equation}
which shows that the system is already in a hamiltonian form, the conjugate momenta being \(\overline{\psi}\) up to a factor. The classical Poisson bracket \(\{\pi,\,\psi\}_{PB} = -1\) is rewritten as \(\{\pi,\,\psi\}_{PB} = -i\), and has the property of being symmetric (this fact will be discussed in a short while).

Quantizing with anticommutators (fermionic systems must be treated this way) one obtains
\[
    \begin{aligned}
        \left\{ \hat{\psi}, \hat{\psi}^{\dagger} \right\} & = i \hbar (-i) = \hbar,                                            \\
        \left\{ \hat{\psi}, \hat{\psi} \right\}           & = \left\{ \hat{\psi}^{\dagger}, \hat{\psi}^{\dagger} \right\} = 0,
    \end{aligned}
\]
that is, the classical variables \(\psi\) and \(\overline{\psi}\) are promoted to linear operators \(\hat{\psi}\) and \(\hat{\psi}^{\dagger}\) satisfying anticommutation relations that are set to be equal to \(i\hbar\) times the value of the classical Poisson brackets. Setting \(\hbar = 1\) for simplicity, one finds the fermionic creation/annihilation algebra
\begin{equation}
    \left\{\hat{\psi},\,\hat{\psi}^{\dagger}\right\} = 1, \quad \left\{\hat{\psi},\,\hat{\psi}\right\} = \left\{\hat{\psi}^{\dagger},\,\hat{\psi}^{\dagger}\right\} = 0.
    \label{eq:fermionic_creation_annihilation_algebra}
\end{equation}
that can be realized in a two-dimensional Hilbert space and with the correct hermiticity properties. If we recall the bosonic harmonic oscillator, we had the algebra of ladder operators defined as
\[
    \left[ \hat{a},\,\hat{a}^{\dagger} \right] = 1, \quad \left[ \hat{a},\,\hat{a} \right] = \left[ \hat{a}^{\dagger},\,\hat{a}^{\dagger} \right] = 0,
\]
which is similar to the fermionic one, but with commutators instead of anticommutators. The main difference is that in the bosonic case, the Hilbert space is infinite-dimensional, while in the fermionic case it is two-dimensional, due to the Pauli exclusion principle.

The Hilbert is explicitly constructed "\textit{à la Fock}", considering \(\hat{\psi}\) as destruction operator and \(\hat{\psi}^{\dagger}\) as creation operator. One starts defining the Fock vacuum \(\ket{0}\), fixed by the condition
\[
    \hat{\psi}\ket{0} = 0.
\]
A second state is obtained by acting with \(\hat{\psi}^{\dagger}\)
\[
    \ket{1} = \hat{\psi}^{\dagger}\ket{0}.
\]
No other state can be obtained acting again with the creation operator \(\hat{\psi}^{\dagger}\), since \((\hat{\psi}^{\dagger})^2 = 0\). Thus the Hilbert space is two-dimensional, spanned by the orthonormal basis \(\{ \ket{0},\,\ket{1} \}\), encapsulating the Pauli exclusion principle at the quantum level.

Normalizing the Fock vacuum to unity, \(\bra{0}\ket{0} = 1\), with \(\bra{0} = \ket{0}^{\dagger}\), one finds that these two states are orthonormal
\[
    \bra{n}\ket{m} = \delta_{nm}, \quad n,\,m = 0,\,1,
\]
and span a two-dimensional Hilbert space, \(\mathcal{F}_2 = \left\{ \ket{0},\,\ket{1} \right\}\). In terms of matrices one computes matrix elements and finds the realization
\[
    \begin{aligned}
        \hat{\psi}           & = \begin{pmatrix}
                                     \bra{0}\hat{\psi}\ket{0} & \bra{0}\hat{\psi}\ket{1} \\
                                     \bra{1}\hat{\psi}\ket{0} & \bra{1}\hat{\psi}\ket{1}
                                 \end{pmatrix} = \begin{pmatrix}
                                                     0 & 1 \\
                                                     0 & 0
                                                 \end{pmatrix},                     \\
        \hat{\psi}^{\dagger} & = \begin{pmatrix}
                                     \bra{0}\hat{\psi}^{\dagger}\ket{0} & \bra{0}\hat{\psi}^{\dagger}\ket{1} \\
                                     \bra{1}\hat{\psi}^{\dagger}\ket{0} & \bra{1}\hat{\psi}^{\dagger}\ket{1}
                                 \end{pmatrix} = \begin{pmatrix}
                                                     0 & 0 \\
                                                     1 & 0
                                                 \end{pmatrix}
    \end{aligned}
\]
acting on the basis
\[
    \ket{0} = \begin{pmatrix}
        1 \\
        0
    \end{pmatrix}, \quad \ket{1} = \begin{pmatrix}
        0 \\
        1
    \end{pmatrix}.
\]

\subsubsection{Hamiltonian Structure and Symplectic Form}
The hamiltonian of the fermionic oscillator is obtained from the Legendre transform of the Lagrangian
\[
    H = \dot{\psi}\pi - L = \omega \overline{\psi} \psi = \frac{\omega}{2} \left( \overline{\psi} \psi - \psi \overline{\psi} \right).
\]
The last form is a classically equivalent way of writing it and is the one that is quantized to resolve the ordering ambiguities
\begin{equation}
    \hat{H} = \frac{\omega}{2} \left( \hat{\psi}^{\dagger} \hat{\psi} - \hat{\psi} \hat{\psi}^{\dagger} \right) = \omega \left( \hat{\psi}^{\dagger} \hat{\psi} - \frac{1}{2} \right).
    \label{eq:fermionic_oscillator_hamiltonian}
\end{equation}
Note that in the Legendre transform, the order of \(\dot{\psi}\) and \(\pi\) matters, and we have used the one that follows from having defined the conjugate momentum in \eqref{eq:conjugate_momenta_fermionic_oscillator} with left derivatives.

Path integrals for fermions can be derived from the canonical formalism, just as in the bosonic case. To this aim, it is useful to rewrite the action in a \textbf{symplectic form}, which is the natural framework for hamiltonian systems.

Let us first review the hamiltonian formalism and the canonical quantization of mechanical systems with Grassmann variables. The hamiltonian formalism aims at producing equations of motion that are first-order differential equations in time. For a simple bosonic model with phase space coordinates \((x,\,p)\), the symplectic form is given by the antisymmetric matrix the \textbf{phase space action} is usually written in the form
\[
    S[x,\,p] = \int \d{t} \left( p \dot{x} - H(x,\,p) \right)
\]

The first term with derivatives (the \(p\dot{x}\) term) is called the symplectic term and fixes the Poisson bracket structure of phase space. Up to total derivatives, it can be written in a more symmetrical form, with the time derivatives shared equally by \(x\) and \(p\) as
\[
    S[x,\,p] = \int \d{t} \frac{1}{2} (p \dot{x} - \dot{p} x) - H(x,\,p) = \int \d{t} \frac{1}{2} z^a \Omega_{ab} \dot{z}^b - H(z),
\]
where we have introduced the phase space vector \(z^a = (x,\,p)\) with \(a=1,\,2\) and the \textbf{symplectic matrix}
\[
    (\Omega^{-1})_{ab} = \begin{pmatrix}
        0 & -1 \\
        1 & 0
    \end{pmatrix}, \quad \Omega^{ab} = \begin{pmatrix}
        0  & 1 \\
        -1 & 0
    \end{pmatrix}.
\]
A symmetric matrix would give terms in the action that are total derivatives and can be dropped (they would not modify the equations of motion).

Thus the action can be written in terms of the symplectic matrix as
\[
    S[z] = \int \d{t} \left[ \frac{1}{2} \begin{pmatrix}
            x & p
        \end{pmatrix} \begin{pmatrix}
            0 & -1 \\
            1 & 0
        \end{pmatrix} \begin{pmatrix}
            \dot{x} \\
            \dot{p}
        \end{pmatrix} - H(x,\,p)\right] = \int \d{t} \left( \frac{1}{2} z^a \left(\Omega^{-1}\right)_{ab} \dot{z}^b  - H(z) \right).
\]
This action produces the correct equations of motion via Hamilton’s equations, which will be of the first order in time derivatives for fermionic systems. As we have said, the first term in the action is symplectic and involves an antisymmetric matrix, which is the reason why the Poisson brackets for fermionic systems are symmetric (in contrast to bosonic systems, where the symplectic form is given by a symmetric matrix and the Poisson brackets are antisymmetric). This is a general feature of fermionic systems, which can be traced back to the anticommuting nature of Grassmann variables.



We can also extend the phase space so that its vector include a generic Grassmann variable: bosonic and fermionic degrees of freedom can be treated in a unified way by introducing the extended phase space variables
\[
    Z^a = \left(x^i,\,p_i,\,\theta^{\alpha}\right) = \left( z^a,\,\theta^{\alpha} \right);
\]
so that the action
\[
    S[Z^a] = \int \d{t} \left(\frac{1}{2}Z^a (\Omega^{-1})_{ab}\dot{Z}^b - H(Z)\right).
\]
Now the symplectic matrix helps into define the Poisson brackets
\[
    \left\{ F,\,G \right\}_{PB} = \frac{\partial_R F}{\partial Z^a} \Omega^{ab} \frac{\partial_L G}{\partial Z^b},
\]
where \(F\) and \(G\) are generic functions of the phase space variables \(Z^a\). The Poisson brackets are symmetric when both \(F\) and \(G\) are Grassmann odd, and antisymmetric otherwise. This is the general structure of hamiltonian systems with both bosonic (\(z^a\) inside \(Z^a\)) and fermionic degrees of freedom (from the included Grassmann variables).

One can find also
\[
    \left\{Z^A,\,Z^B\right\}_{PB} = \Omega^{AB},
\]
indeed, the symplectic matrix for the fermionic oscillator can be read as block diagonal, with the bosonic sector given by a symmetric matrix and the fermionic sector by an antisymmetric one
\[
    OMEGA MATRIX
\]


[...]

The properties of the Poisson brackets make it consistent to adopt the canonical quantization rules, that consist in promoting the phase space coordinates \(Z^A\) to operators \(\hat{Z}^A\) with commutation/anticommutation relation fixed by their classical Poisson brackets
\[
    \left[ \hat{Z}^A, \hat{Z}^B \right\} = i\hbar \left\{Z^{A},\,Z^{B} \right\}= i \hbar \Omega^{AB},
\]
where we have employed the compact notation
\[
    \left[ \cdot,\, \cdot \right\} = \begin{dcases}
        \left\{\cdot,\,\cdot\right\} & \text{ if both variables are fermionic}, \\
        \left[\cdot,\,\cdot\right]   & \text{ otherwise}.
    \end{dcases}
\]
often called \textbf{“graded commutator”}. The graded commutator satisfies identities similar to those for the Poisson brackets in (163), and makes it consistent to adopt the given quantization rules. This quick exposition becomes clearer by working through simple examples.

\begin{example}
    Single real Grassmann variable \(\psi\) (“single Majorana fermion in one dimension”). Taking as phase space lagrangian
    \[
        L = \frac{i}{2}\psi\dot{\psi} - H(\psi),
    \]
    which is formally real and produces equations of motion of the first order in time, one finds \(\Omega^{-1}=i\) and \(\Omega=-i\), and Poisson bracket at equal times \(\left\{\psi, \psi\right\}_{PB} = -i\). The dynamical variable \(\psi(t)\) is often called a Majorana fermion in one dimension, as it satisfies the Dirac equation in one dimension plus a reality condition (akin to the Majorana condition used in four dimensions).

    One notices that the only possible Grassmann even hamiltonian is a constant, so that the model is rather trivial. One verifies in this example that the phase space can be odd-dimensional if Grassmann variables are present. The model is quantized by introducing the hermitian operator \(\hat{\psi}\) with anticommutator
    \[
        \left\{\hat{\psi},\,\hat{\psi} \right\} = \hbar,
    \]
    The quantum theory is also trivial, as one represents irreducibly this algebra in a one-dimensional Hilbert space, with the operator \(\hat{\psi}\) acting as multiplication by the constant \(\sqrt{\hbar/2}\). This Hilbert space has no room for any nontrivial dynamics, as there is only the vacuum state.
\end{example}

\begin{example}
    Several real Grassmann variables \(\psi^i\) (“Majorana fermions in one dimension”). For the case of several real Grassmann variables, one may take as phase space lagrangian
    \[
        L = \frac{i}{2} \psi^i \delta_{ij} \dot{\psi}^j - H(\psi),\quad i,j = 1,\,\dots,\,n,
    \]
    which is formally real and produces equations of motion of the first order in time. One finds \((\Omega^{-1})_{ij} = i \delta_{ij}\) and \(\Omega^{ij} = -i \delta^{ij}\), and Poisson brackets at equal times
    \[
        \left\{\psi^i,\,\psi^j\right\}_{PB} = -i \delta^{ij}.
    \]
    The model is quantized by introducing the hermitian operators \(\hat{\psi}^i\) with anticommutators
    \[
        \left\{\hat{\psi}^i,\,\hat{\psi}^j\right\} = \hbar \delta^{ij}.
    \]
    This algebra can be represented irreducibly in a Hilbert space of dimension \(2^{\lfloor n/2 \rfloor}\) if \(n\) is even, and \(2^{\lfloor n/2 \rfloor + 1}\) if \(n\) is odd. The operators \(\hat{\psi}^i\) can be represented in terms of gamma matrices of a Euclidean space of dimension \(n\), satisfying the Clifford algebra
    \[
        \left\{\gamma^i,\,\gamma^j\right\} = 2 \delta^{ij}.
    \]
\end{example}

\begin{example}
    duh trei
\end{example}

\begin{example}
    duh patru
\end{example}

\subsection{Coherent States}\label{sec:coherent_states_fermions}

It is useful to introduce coherent states, an overcomplete basis of vectors for the fermionic Fock space described previously, for deriving a path integral for fermionic systems. They provide ket eigenstates of the fermionic operator \(\hat{\psi}\) with Grassmann-valued eigenvalues. Together with a resolution of the identity, they allow to convert the matrix elements of the quantum evolution operator (transition amplitudes) into a path integral where one sums over Grassmann valued functions.

We first review the construction of bosonic coherent states, used in the theory of the harmonic oscillator, as a guide on the construction in the fermionic case. In the theory of the harmonic oscillator, one introduces coherent states defined as eigenstates of the annihilation operator \(\hat{a}\). Let us recall the algebra of the creation and annihilation operators \(\hat{a}^\dagger\) and \(\hat{a}\)
\[
    \left[\hat{a}, \hat{a}^\dagger \right] = 1, \quad \left[\hat{a}, \hat{a} \right] = \left[\hat{a}^\dagger, \hat{a}^\dagger \right] = 0.
\]

It is realized by operators acting on an infinite dimensional Hilbert space, identified with a Fock space constructed as follows. A complete orthonormal basis of the Fock space is obtained by starting from the Fock vacuum \(\ket{0}\), defined by the condition \(\hat{a} \ket{0} = 0\). The other states of the basis are obtained by acting with the creation operator \(\hat{a}^\dagger\) an arbitrary number of times on the Fock vacuum \(\ket{0}\)
\[
    \begin{aligned}
        \ket{0} & \text{ such that } \hat{a} \ket{0} = 0,            \\
        \ket{1} & = \hat{a}^\dagger \ket{0},                         \\
        \ket{2} & = \frac{1}{\sqrt{2!}} (\hat{a}^\dagger)^2 \ket{0}, \\
        \vdots  &                                                    \\
        \ket{n} & = \frac{1}{\sqrt{n!}} (\hat{a}^\dagger)^n \ket{0}.
    \end{aligned}
\]
Normalizing the Fock vacuum to the unit norm, \(\bra{0}\ket{0} = 1\) where \(\bra{0} = \ket{0}^\dagger\), one finds that these states are orthonormal
\[
    \bra{m}\ket{n} = \delta_{mn}, \quad m,\,n = 0,\,1,\,2,\,\dots,
\]

Now, choosing a complex number \(a\), one builds a coherent state \(\ket{a}\) as the eigenstate of the annihilation operator \(\hat{a}\) with eigenvalue \(a\)
\[
    e^{a \hat{a}^{\dagger}}, \quad \hat{a} \ket{a} = a \ket{a}.
\]
A way of proving this is by expanding the exponential and viewing \(\ket{a}\) as an infinite sum with suitable coefficients of the basis vectors of the Fock space
\[
    \ket{a} = \left( 1 + a \hat{a}^\dagger + \frac{1}{2!} (a\hat{a}^\dagger)^2 + \cdots \right)\ket{0} = \sum_{n=0}^{\infty} \frac{a^n}{\sqrt{n!}} \ket{n}.
\]
One may verify explicitly that \(\hat{a} \ket{a} = a \ket{a}\) by acting with \(\hat{a}\) on the above expansion and using the action of \(\hat{a}\) on the basis states \(\ket{n}\).

    [...]

A set of properties can be proven by direct computation:
\begin{itemize}
    \item \(\bra{\overline{a}} = \ket{a}^\dagger = \bra{0} e^{\overline{a} \hat{a}}\) is the dual coherent state, eigenstate of the creation operator \(\hat{a}^\dagger\) with eigenvalue \(\overline{a}\)
          \[
              \bra{\overline{a}} \hat{a}^\dagger = \overline{a} \bra{\overline{a}};
          \]
    \item the \textbf{scalar product} between two coherent states is
          \[
              \bra{\overline{a}} \ket{a} = e^{\overline{a} a};
          \]
    \item the set of coherent states provides a \textbf{resolution of the identity}
          \[
              \mathbb{I} = \int \frac{\mathrm{d} \overline{a} \mathrm{d} a}{2\pi i} e^{-\overline{a} a} \ket{a} \bra{\overline{a}},
          \]
          where the integration measure is defined as \(\mathrm{d} \overline{a} \mathrm{d} a = \mathrm{d} (\Re a) \mathrm{d} (\Im a)\);
    \item the \textbf{trace} of an operator \(\hat{O}\) can be computed as
          \[
              \text{Tr}\, \hat{O} = \int \frac{\mathrm{d} \overline{a} \mathrm{d} a}{2\pi i} e^{-\overline{a} a} \bra{\overline{a}} \hat{O} \ket{a}.
          \]
\end{itemize}
One should note that the set of coherent states forms an over-complete basis, in particular, they are not orthonormal, in fact \(\bra{\overline{b}}\ket{a} = e^{\overline{b} a} \neq 0\). However, it is useful to keep this redundancy.

Coherent states may be used to rederive a form of the path integral in phase space in terms of the so-called holomorphic trajectories, corresponding to paths for the \(a(t)\) and \(\overline{a}(t)\) variables. We will not present it here but consider only the corresponding fermionic construction, which is, mutatis mutandis, analogous.

    [...]

\subsubsection{Fermionic Coherent States}

We now turn to the construction of coherent states for fermionic systems, that is, for systems described in terms of fermionic creation/annihilation operators \(\hat{\psi}^\dagger\) and \(\hat{\psi}\) satisfying the algebra \eqref{eq:fermionic_creation_annihilation_algebra}. The construction is similar to the bosonic case, thus we arrive at a description of the space given by eigenstates of the fermionic field operators, but with Grassmann-valued eigenvalues this time. One introduces two Grassmann variables \(\psi\) and \(\overline{\psi}\), and defines the coherent state \(\ket{\psi}\) as
\[
    \ket{\psi} = e^{\hat{\psi}^\dagger \psi} \ket{0}, \quad \hat{\psi} \ket{\psi} = \psi \ket{\psi},
\]
where \(\ket{0}\) is the Fock vacuum defined by \(\hat{\psi} \ket{0} = 0\). We also have
\[
    \bra{\overline{\psi}} = \bra{0} e^{\overline{\psi} \hat{\psi}}, \quad \bra{\overline{\psi}} \hat{\psi}^\dagger = \bra{\overline{\psi}} \overline{\psi}.
\]
The properties of fermionic coherent states can be summarized as follows:
\begin{enumerate}
    \item the \textbf{scalar product} between two coherent states is
          \[
              \bra{\overline{\psi}} \ket{\psi} = e^{\overline{\psi} \psi};
          \]
    \item the set of coherent states provides a \textbf{resolution of the identity}
          \[
              \mathbb{I} = \int \mathrm{d} \overline{\psi} \mathrm{d} \psi e^{-\overline{\psi} \psi} \ket{\psi} \bra{\overline{\psi}},
          \]
          where the integration measure is defined as \(\mathrm{d} \overline{\psi} \mathrm{d} \psi = \d{\psi} \d{\overline{\psi}}\);
    \item the \textbf{trace} of an operator \(\hat{O}\) can be computed as
          \[
              \text{Tr}\, \hat{O} = \int \mathrm{d} \overline{\psi} \mathrm{d} \psi e^{-\overline{\psi} \psi} \bra{-\overline{\psi}} \hat{O} \ket{\psi}.
          \]
    \item the \textbf{supertrace} of an operator \(\hat{O}\) is defined as
          \[
              \text{Str}\, \hat{O} = \text{Tr}\, [(-1)^F \hat{O}] = \int \mathrm{d} \overline{\psi} \mathrm{d} \psi e^{-\overline{\psi} \psi} \bra{\overline{\psi}} \hat{O} \ket{\psi},
          \]
          where \(F\) is the fermion number operator, defined by its action on the Fock basis states as \(F \ket{0} = 0\) and \(F \ket{1} = 1\).
\end{enumerate}
We can now prove these properties by direct computation, using the definitions of the coherent states and the properties of Grassmann variables and fermionic operators.

\paragraph{(0)} At first, the definitions of the coherent states imply immediately the eigenvalue equations for the annihilation and creation operators
\[
    \begin{aligned}
        \ket{\psi}            & = e^{\hat{\psi}^\dagger \psi} \ket{0} = \left( 1 + \hat{\psi}^\dagger \psi \right) \ket{0}                                      \\
                              & = \ket{0} + \psi \ket{1}, \implies \hat{\psi} \ket{\psi} = \psi \ket{\psi},                                                     \\
        \bra{\overline{\psi}} & = \bra{0} e^{\overline{\psi} \hat{\psi}} = \bra{0} \left( 1 + \overline{\psi} \hat{\psi} \right)                                \\
                              & = \bra{0} + \overline{\psi} \bra{1}, \implies \bra{\overline{\psi}} \hat{\psi}^\dagger = \bra{\overline{\psi}} \overline{\psi}.
    \end{aligned}
\]
Note that terms proportional to \(\psi^2\) can be inserted or eliminated at wish, as they vanish due to the Grassmann property \(\psi^2 = 0\).

\paragraph{(1)} The scalar product between two coherent states is computed as
\[
    \bra{\overline{\psi}} \ket{\psi} = \bra{0} (1 + \overline{\psi} \hat{\psi}) (1 + \hat{\psi}^\dagger \psi) \ket{0} = \left(\bra{0} - \bra{1}\overline{\psi}\right)\left( \ket{0} - \psi \ket{1}\right) = 1 + \overline{\psi} \psi = e^{\overline{\psi} \psi}.
\]
We point out that the Grassmann variables are here defined to commute with the Fock vacuum \(\ket{0}\), so that they commute with the coherent states, but anticommute with \(\ket{1} = \hat{\psi}^\dagger \ket{0}\) (as they anticommute with \(\hat{\psi}^\dagger\)).

\paragraph{(2)} The resolution of the identity is proven by direct computation. Computing the completeness relation, one finds
\[
    \mathbb{I} = \ket{0}\bra{0} + \ket{1}\bra{1} = \int \mathrm{d} \overline{\psi} \mathrm{d} \psi e^{-\overline{\psi} \psi} \left( \ket{0} + \psi \ket{1} \right) \left( \bra{0} + \overline{\psi} \bra{1} \right).
\]
Now we can compute the Berezin integrals remembering that \(\int \d{\psi} = \frac{\partial}{\partial \psi}\). Expanding the exponential and the product, one finds
\[
    \mathbb{I} = \frac{\partial}{\partial \psi} \frac{\partial}{\partial \overline{\psi}} \left( 1 - \overline{\psi} \psi \right) \left( \ket{0}\bra{0} + \overline{\psi} \ket{0}\bra{1} + \psi \ket{1}\bra{0} + \overline{\psi} \psi \ket{1}\bra{1} \right).
\]

\paragraph{(3)} The trace of an operator \(\hat{O}\) is computed as \dots

\paragraph{(4)} The supertrace of an operator \(\hat{O}\) is computed as \dots

The generalization to more fermionic degrees of freedom is straightforward.

\subsection{Fermionic Path Integrals}

We now have all the tools to find a path integral representation of the transition amplitude between coherent states
\[
    \bra{\overline{\psi}_f} e^{-i \hat{H} T} \ket{\overline{\psi}_i},
\]
where we set \(\hbar=1\) for notational simplicity. We consider an hamiltonian \(\hat{H}(\hat{\psi}^\dagger, \hat{\psi})\) written in such a way that all creation operators are on the left of the annihilation operators, something that is always possible to achieve using the fundamental anticommutation relations. Note also that for a single pair of fermionic creation/annihilation operators, the most general (bosonic) hamiltonian takes the simple form \(\hat{H} = \omega \hat{\psi}^\dagger \hat{\psi} + h_0\), with \(\omega\) and \(h_0\) real constants.

To turn the transition amplitude into a path integral, one divides the total propagation time \(T\) into \(N\) steps of duration \(\epsilon = T / N\), so that \(T = N\epsilon\). Using \(N-1\) times the decomposition of the identity in terms of coherent states, one gets the following equalities
\[
    \begin{aligned}
        \bra{\overline{\psi}_f} e^{-i \hat{H} T} \ket{\overline{\psi}_i} & = \bra{\overline{\psi}_f} \left( e^{-i \hat{H} \epsilon} \right)^N \ket{\overline{\psi}_i} \quad N \text{ exponentials and } N-1 \text{ identities}                                       \\
                                                                         & = \int \prod_{k=1}^{N-1} \mathrm{d} \overline{\psi}_k \mathrm{d} \psi_k e^{-\overline{\psi}_k \psi_k} \prod_{k=1}^{N} \bra{\overline{\psi}_{k}} e^{-i \hat{H} \epsilon} \ket{\psi_{k-1}}, \\
    \end{aligned}
\]
where we have defined \(\psi_0 \equiv \psi_i\) and \(\overline{\psi}_N \equiv \overline{\psi}_f\). For \(\epsilon \to 0\), one can approximate the elementary transition amplitudes as
\[
    \bra{\overline{\psi}_{k}} e^{-i \hat{H} \epsilon} \ket{\psi_{k-1}} \approx \bra{\overline{\psi}_{k}} \left( 1 - i \hat{H} \epsilon \right) \ket{\psi_{k-1}} = \bra{\overline{\psi}_{k}} \ket{\psi_{k-1}} - i \epsilon \bra{\overline{\psi}_{k}} \hat{H} \ket{\psi_{k-1}}.
\]
The substitution \(\hat{H}(\hat{\psi}^\dagger, \hat{\psi}) \to H(\overline{\psi}_k, \psi_{k-1})\) follows from the ordering of the hamiltonian specified previously (\(\hat{\psi}^\dagger\) on the left and \(\hat{\psi}\) on the right). This allows one to act with the creation operator on a bra eigenstate, and with the annihilation operator on a ket eigenstate, so that all operators in the hamiltonian get substituted by the respective eigenvalues, producing a function of these Grassmann numbers. This way, the hamiltonian operator \(\hat{H}(\hat{\psi}^\dagger, \hat{\psi})\) gets substituted by the hamiltonian function \(H(\overline{\psi}_k, \psi_{k-1})\). These approximations are valid for \(N \to \infty\), i.e. \(\epsilon \to 0\), so that we can write
\[
    \bra{\psi_{k}} e^{-i \hat{H} \epsilon} \ket{\psi_{k-1}} \approx e^{\overline{\psi}_k \psi_{k-1}} e^{- i \epsilon H(\overline{\psi}_k, \psi_{k-1})}.
\]
Thus we can reinsert this expression into the previous formula for the transition amplitude, obtaining
\[
    \begin{aligned}
        \bra{\overline{\psi}_f} e^{-i \hat{H} T} \ket{\overline{\psi}_i} & = \int \prod_{k=1}^{N-1} \mathrm{d} \overline{\psi}_k \mathrm{d} \psi_k \exp\left\{ \sum_{k=1}^{N} \left[ \overline{\psi}_k \psi_{k-1} - \overline{\psi}_k \psi_k - i \epsilon H(\overline{\psi}_k, \psi_{k-1}) \right] \right\}                                                        \\
                                                                         & = \int \mathrm{D} \overline{\psi} \mathrm{D} \psi \exp\left\{ \int_0^T \mathrm{d}t \left[ \overline{\psi}(t) \frac{\partial}{\partial t} \psi(t) - i H(\overline{\psi}(t), \psi(t)) \right] \right\} = \int \mathrm{D} \overline{\psi} \mathrm{D} \psi e^{i S[\overline{\psi},\,\psi]}.
    \end{aligned}
\]
This is the path integral for one complex fermionic degree of freedom. We recognize in the exponent the discretization of the classical action
\[
    S[\overline{\psi},\,\psi] = \int_0^T \mathrm{d}t \left[ i \overline{\psi}(t) \frac{\partial}{\partial t} \psi(t) - H(\overline{\psi}(t), \psi(t)) \right], \rightarrow S[\psi,\,\overline{\psi}] = \sum_{k=1}^N \epsilon \left[ i \overline{\psi}_k \frac{\psi_k - \psi_{k-1}}{\epsilon} - H(\overline{\psi}_{k}, \psi_{k-1}) \right] -i \overline{\psi}_N \psi_N,
\]

where \(T = N \epsilon\) is the total propagation time. The discrete values \(\psi_k\) and \(\overline{\psi}_k\) are those corresponding to the values of the continuous functions evaluated at times \(t = k\epsilon\), i.e. \(\psi_k = \psi(k\epsilon)\) and \(\overline{\psi}_k = \overline{\psi}(k\epsilon)\). The last way of writing the amplitude in (197) is symbolic and indicates the formal sum over all paths \(\overline{\psi}(t), \psi(t)\) with boundary conditions \(\psi(0) = \psi_0 \equiv \psi_i\) and \(\overline{\psi}(T ) = \overline{\psi}_N \equiv \overline{\psi}_f\), weighed by the exponential of \(i\) times the classical action \(S[\overline{\psi}, \psi]\). Note that the action contains the boundary term \(-i \overline{\psi}(T) \psi(T)\). It is essential for formulating a variational principle where the boundary data are fixed by specifying the initial value of the function \(\psi(t)\) and the final value of the function \(\overline{\psi}(t)\) (i.e. \(\psi(0) = \psi_i\) and \(\overline{\psi}(T ) = \overline{\psi}_f\)).

\paragraph{Trace.}

\paragraph{Supertrace.}

\subsection{Correlation Functions}

Correlation functions are defined as normalized averages of the dynamical variables. Similar to the bosonic case, a generating functional can be introduced by incorporating sources into the path integral formulation. Using a hypercondensed notation, all fermionic fields are represented by \(\psi^i\) and the corresponding sources denoted by \(\eta_i\) are taken to be Grassmann-valued variables as well. Then, the generating functional for correlation functions is expressed as follows:
\[
    Z[\eta] = \int \mathrm{D} \psi \, e^{i \left( S[\psi] + \eta_i \psi^i \right)}.
\]
As an example, the two-point function is given by
\[
    \langle \psi^{i} \psi^{j} \rangle = \frac{1}{Z[0]} \left. \left(\frac{1}{i}\right)^2\frac{\delta^2 Z[\eta]}{\delta \eta_i \delta \eta_j} \right|_{\eta=0}.
\]

In a free theory, identified by a quadratic action of the form
\[
    S[\psi] = \frac{1}{2} \psi^i K_{ij} \psi^j,
\]
with \(K_{ij}\) an antisymmetric matrix, one formally computes the path integral with sources by gaussian integration (after completing squares in terms of \(\psi^i + G^{ij} \eta_j \) and using the transitional invariance of the measure). The answer takes the form
\[
    Z[\eta] = Z[0] e^{-\frac{i}{2} \eta_i G^{ij} \eta_j} = \sqrt{\det K_{ij}} \, e^{-\frac{i}{2} \eta_i G^{ij} \eta_j},
\]
where \(G^{ij}\) is the inverse of the kinetic operator \(K_{ij}\), defined by the relation
\[
    K_{ij} G^{jk} = \delta_i^k.
\]
The two-point function is then found to be
\[
    \langle \psi^{i} \psi^{j} \rangle = -i G^{ij},
\]
which lead us to identify \(G^{ij}\) as the fermionic propagator of the theory, the Green function in quantum mechanical applications. To check the overall normalization, one must be careful with signs arising from the anticommuting character of the Grassmann variables and from the antisymmetric properties of \(K_{ij}\) and \(G^{ij}\). Similar formulae may be written down for complex fermions (they are contained in the above formula as well, for example setting \(\psi^i \equiv (\psi^a, \overline{\psi}_a)\)). As they apply to the case of a Dirac fermion, let us write down the main formulae for the variables \(\psi^i\) with complex conjugates \(\overline{\psi}_i\)
\[
    \begin{aligned}
        Z[\eta,\,\overline{\eta}]                  & = \int \mathrm{D} \psi \mathrm{D} \overline{\psi} \, e^{i \left( S[\psi,\,\overline{\psi}] + \overline{\eta}_i \psi^i + \overline{\psi}_i \eta^i \right)} = \det K^i_{j} \, e^{i \overline{\eta}_i G^{i}_j \eta^j}, \\
        \langle \psi^{i} \overline{\psi}_j \rangle & = \frac{1}{Z[0,\,0]} \left. \left(\frac{1}{i}\right)^2\frac{\delta^2 Z[\eta,\,\overline{\eta}]}{\delta \overline{\eta}_i \delta \eta^j} \right|_{\eta=\overline{\eta}=0} = -i G^{i}_j,
    \end{aligned}
\]
where the results are obtained for a free theory with quadratic action
\[
    S[\psi,\,\overline{\psi}] = \overline{\psi}_i K^i_{j} \psi^j,
\]
and \(Z[\eta, \overline{\eta}]\) has been computed completing the squares in the path integral (using \(G^i_j\), the inverse of the kinetic operator \(K^i_j\)). Suitable boundary conditions are implicit in the path integral and Green functions \(G^i_j\). The entire set of generating functionals discussed in the bosonic case can similarly be introduced here.\TODO{compute it if you want} Let us consider the examples of the fermionic oscillator and Dirac field. The fermionic oscillator has classical action (see eq. \eqref{eq:fermionic_oscillator_action})
\[
    S[\psi,\,\overline{\psi}] = \int \mathrm{d}t \overline{\psi}(t) \left[ i \frac{\partial}{\partial t} - \omega \right] \psi(t),
\]
and the path integral with sources is computed by completing squares
\[
    \begin{aligned}
        Z[\eta,\,\overline{\eta}] & = \int \mathrm{D} \psi \mathrm{D} \overline{\psi} \, e^{i \left( S[\psi,\,\overline{\psi}] + \int \mathrm{d}t \left[ \overline{\eta}(t) \psi(t) + \overline{\psi}(t) \eta(t) \right] \right)} \\
                                  & = N \exp{i \int \int \mathrm{d}t \mathrm{d}t' \overline{\eta}(t) G(t - t') \eta(t')},
    \end{aligned}
\]
where \(G(t-t^{\prime})\) is the Green function of the operator \(K = -i \partial_t + \omega\), with
\[
    \left(-i\partial_t + \omega\right) G(t - t') = \delta(t - t'),
\]
and reads:
\[
    G(t-t^{\prime}) = \int \frac{\d{p}}{2\pi} \frac{e^{-i p (t - t')}}{-p + \omega} = \int \frac{\d{p}}{2\pi} e^{-i p (t - t')} \frac{p+\omega}{-p^2 + \omega^2 - i\epsilon} = i \theta(t - t') e^{-i \omega (t - t')}.
\]
As usual, the \(i\epsilon\) prescription has been introduced to define the propagator properly. The two-point function is then found to be
\[
    \langle \psi(t) \overline{\psi}(t') \rangle = -i G(t - t') = \theta(t - t') e^{-i \omega (t - t')}.
\]

Similar considerations apply to the \textbf{Dirac field}, with classical action
\[
    S[\psi,\,\overline{\psi}] = \int \mathrm{d}^4 x \, \overline{\psi}(x) \left( i \gamma^\mu \partial_\mu - m \right) \psi(x),
\]
and path integral with sources
\[
    \begin{aligned}
        Z[\eta,\,\overline{\eta}] & = \int \mathrm{D} \psi \mathrm{D} \overline{\psi} \, e^{i \left( S[\psi,\,\overline{\psi}] + \int \mathrm{d}^4 x \left[ \overline{\eta}(x) \psi(x) + \overline{\psi}(x) \eta(x) \right] \right)} \\
                                  & = N \exp{i \int \int \mathrm{d}^4 x \mathrm{d}^4 y \overline{\eta}(x) G(x - y) \eta(y)},
    \end{aligned}
\]
where \(G(x-y)\) is the Green function of the operator \(K = i \gamma^\mu \partial_\mu + m = \slashed{\partial} + m\), with
\[
    \left( i \gamma^\mu \partial_\mu + m \right) G(x - y) = \delta^{(4)}(x - y),
\]
and reads:
\[
    G(x-y) = \int \frac{\mathrm{d}^4 p}{(2\pi)^4} e^{i p^{\mu} (x^{\mu} - y^{\mu})} \frac{(-i\slashed{p} + m)}{p^2 + m^2 - i\epsilon}.
\]
It is often indicated also by \(S(x-y)\) (S for spinor). The two-point function (propagator) then becomes
\[
    \langle \psi(x) \overline{\psi}(y) \rangle = -i G(x - y) = -\int \frac{\mathrm{d}^4 p}{(2\pi)^4} e^{i p^{\mu} (x^{\mu} - y^{\mu})} \frac{(\slashed{p} + im)}{p^2 + m^2 - i\epsilon}.
\]
which is interpreted as describing a particle propagating from \(y^{\mu}\)  to \(x^{\mu}\) if \(x^0 > y^0\), or an antiparticle propagating from \(x^{\mu}\) to \(y^{\mu}\) if \(y^0 > x^0\).

Wick's theorem and perturbation theory for fermionic systems can be developed similarly to the bosonic case, with suitable signs arising from the anticommuting nature of the Grassmann variables.To conclude, a last remark: a well-known property of perturbation theory written in terms of Feynman diagram (and related Feynman rules that translate them into equations) states that fermionic loops carry a minus sign. This is easily seen as arising for the Grassmann character of the fermionic variables. In a hypercondensed notation, the free propagator is denoted by
\[
    \langle \psi^i \overline{\psi}_j \rangle = \feynLine,
\]
and considering an interaction of the form \(S_{int} = \lambda \overline{\psi}_i \psi^i\), one finds in diagrams arising from the expansion of the Dyson formula \(\langle e^{i S_{int}} \rangle\)  terms of the form
\[
    \langle S_{int}^2 \rangle_c = \lambda^2 \langle \overline{\psi}_i \psi^i \overline{\psi}_j \psi^j \rangle_c = - \lambda^2 \langle \psi^j \overline{\psi}_i \rangle \langle \psi^j \overline{\psi}_i \rangle = \feynLoop.
\]
